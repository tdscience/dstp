[
  {
    "objectID": "prerequisites.html",
    "href": "prerequisites.html",
    "title": "Prerequisites",
    "section": "",
    "text": "This course assumes working knowledge with R or Python for research. We assume that you are already comfortable with an integrated development environment (IDE), such as RStudio or VS Code. You must have a GitHub account and it will be beneficial to be familiar with the concepts of version control, although we will cover these in the course.\nFamiliarity with referencing software such as Zotero (recommended) and bibliography file formats such as BibTeX will be beneficial, but not essential.",
    "crumbs": [
      "Prerequisites"
    ]
  },
  {
    "objectID": "prerequisites.html#course-prerequisites",
    "href": "prerequisites.html#course-prerequisites",
    "title": "Prerequisites",
    "section": "",
    "text": "This course assumes working knowledge with R or Python for research. We assume that you are already comfortable with an integrated development environment (IDE), such as RStudio or VS Code. You must have a GitHub account and it will be beneficial to be familiar with the concepts of version control, although we will cover these in the course.\nFamiliarity with referencing software such as Zotero (recommended) and bibliography file formats such as BibTeX will be beneficial, but not essential.",
    "crumbs": [
      "Prerequisites"
    ]
  },
  {
    "objectID": "prerequisites.html#software-prerequisites",
    "href": "prerequisites.html#software-prerequisites",
    "title": "Prerequisites",
    "section": "2 Software Prerequisites",
    "text": "2 Software Prerequisites\nYou should bring a laptop with the following software installed and tested to check it works:\n\nQuarto (minimum version: 1.5.45)\nA tested R or Python installation or both (note: if you have Docker installed you should be able to run R and Python inside a devcontainer, works best with VS Code)\nRStudio or VS Code IDE\n\nIf you use RStudio, it should ‘just work’ with R and Quarto.\nIf you will use VS Code for the course, you need the following extensions:\n\nThe R extension reditorsupport.r if using R\nThe Python extension ms-python.python if using Python\nThe quarto extention quarto.quarto\n\nFor experienced users: you can also use an IDE of your choice, for example Positron IDE which is based on VS Code and has R, Python and Quarto support built-in.\n\nGit, installed with one of the following packages:\n\nGitHub Desktop (see desktop.github.com)\nGit for the command line (see git-scm.com)\n\nThe gh command-line tool (see cli.github.com for installation and set-up instructions)",
    "crumbs": [
      "Prerequisites"
    ]
  },
  {
    "objectID": "prerequisites.html#recommended-online-courses",
    "href": "prerequisites.html#recommended-online-courses",
    "title": "Prerequisites",
    "section": "3 Recommended Online Courses",
    "text": "3 Recommended Online Courses\nStudents should take these short but very useful online courses to prepare:\n\nIntro to GitHub (should take less than an hour)\nCommunicate using Markdown (should take around 30 minutes or less)",
    "crumbs": [
      "Prerequisites"
    ]
  },
  {
    "objectID": "prerequisites.html#testing-your-setup",
    "href": "prerequisites.html#testing-your-setup",
    "title": "Prerequisites",
    "section": "4 Testing your setup",
    "text": "4 Testing your setup\nYou can test your setup by running the following code in R or Python.\n\nRPython\n\n\n\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!require(\"remotes\")) install.packages(\"remotes\")\npkgs = c(\n    \"sf\",\n    \"tidyverse\",\n    \"tmap\",\n    \"data.table\",\n    \"stats19\",\n    \"quarto\",\n    \"stplanr\",\n    \"osmextract\",\n    \"zonebuilder\"\n)\npkgs_to_install = pkgs[!pkgs %in% installed.packages()[, \"Package\"]]\nif (length(pkgs_to_install) &gt; 0) {\n  install.packages(pkgs_to_install)\n}\nlibrary(tidyverse)\nzones = zonebuilder::zb_zone(\"Leeds\", n_circles = 3)\nstudy_area = zones |&gt;\n  sf::st_union()\nextra_tags = c(\n  \"maxspeed\",\n  \"lit\",\n  \"cycleway\"\n)\nosm_network = osmextract::oe_get(\n  place = \"Leeds, UK\",\n  boundary = study_area,\n  boundary_type = \"clipsrc\",\n  extra_tags = extra_tags\n)\n\n\nosm_network |&gt;\n  select(maxspeed) |&gt;\n  plot()\n\n\n\n\n\n\n\nsf::write_sf(study_area, \"leeds_study_area.geojson\")\n\n\n\n\nimport osmnx as ox\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport shapely\n\nstudy_point = shapely.Point(-1.55, 53.80)  # Latitude and Longitude for Leeds\nstudy_geom = gpd.GeoSeries([study_point], crs=4326)\nstudy_polygon = study_geom.to_crs(epsg=3857).buffer(6000).to_crs(epsg=4326).unary_union\nstudy_polygon_gpd = gpd.GeoDataFrame(geometry=[study_polygon], crs=\"EPSG:4326\")\n# Read-in geojson already saved from R\nstudy_polygon = gpd.read_file(\"leeds_study_area.geojson\")\n# study_polygon_gpd.explore()\ntags = {\"highway\": True, \"maxspeed\": True, \"lit\": True, \"cycleway\": True}\ngdf = ox.features_from_polygon(study_polygon, tags)\ngdf = gdf[gdf.geom_type.isin([\"LineString\", \"MultiLineString\"])]\ngdf = gdf.to_crs(epsg=3857)\ngdf.plot(column=\"maxspeed\", figsize=(10, 10), legend=True)\nplt.show()\n\n\n\n\nLet us know how you get on and let us know if you have any issues getting set up, either by email, or (preferably) via the Discussion forum on GitHub associated with this course repository at github.com/tdscience/dstp/discussions.",
    "crumbs": [
      "Prerequisites"
    ]
  },
  {
    "objectID": "collisions.html",
    "href": "collisions.html",
    "title": "Road traffic collisions",
    "section": "",
    "text": "1 Road traffic collisions\nPlaceholder for road traffic collisions example.\nThis page will contain an analysis using stats19 data for Leeds.\n\n\n\n\nReuseCC BY-SA 4.0Copyright© 2025 Robin Lovelace",
    "crumbs": [
      "Examples",
      "Road traffic collisions"
    ]
  },
  {
    "objectID": "s5.html",
    "href": "s5.html",
    "title": "Routing and route network analysis",
    "section": "",
    "text": "Placeholder for session 5 content.\n\n\n\nReuseCC BY-SA 4.0Copyright© 2025 Robin Lovelace"
  },
  {
    "objectID": "s6.html",
    "href": "s6.html",
    "title": "Best practices for data science in transport planning",
    "section": "",
    "text": "Placeholder for session 6 content.\n\n\n\nReuseCC BY-SA 4.0Copyright© 2025 Robin Lovelace"
  },
  {
    "objectID": "s2.html",
    "href": "s2.html",
    "title": "Origin-destination data analysis",
    "section": "",
    "text": "Origin-destination (OD) data forms the backbone of transportation planning, urban analytics, and spatial mobility research. This type of data captures movement patterns between geographic locations, revealing how people, goods, or services flow through space. Understanding OD data is crucial for making informed decisions such as infrastructure development and public transport planning.\nIn this session, we will how to use and analyse geographic and origin-destination data. It includes:\n\nA short lecture on geographic and origin-destination data (see slides)\nHands-on analysis: Working with various geographic and OD datasets\n\n\n\nYou need to have a number of packages installed and loaded. Install the packages by typing in the following commands into RStudio (you do not need to add the comments after the # symbol)\nIf you need to install any of these packages use:\n\nRPython\n\n\n\nif (!require(\"pak\")) install.packages(\"pak\")\npak::pkg_install(c(\"sf\", \"tidyverse\", \"remotes\", \"ggspatial\", \"tmap\"))\n\n\nlibrary(sf)        # vector data package\nlibrary(tidyverse) # tidyverse packages\nlibrary(ggspatial) # ggspatial package\nlibrary(spData)    # spatial data package\n\n\n\n\n# Install necessary packages (uncomment if not already installed)\n# !pip install geopandas pandas matplotlib seaborn\n\nimport geopandas as gpd       # vector data package\nimport pandas as pd           # data manipulation\nimport matplotlib.pyplot as plt  # plotting\nimport seaborn as sns            # advanced plotting\n# For spatial data, geopandas comes with sample datasets\n# Alternatively, we can use the naturalearth datasets\nimport geopandas.datasets\n\n\n\n\n\nCheck your packages are up-to-date with update.packages() in R (or equivalent in Python)\nCreate a project folder with an appropriate name for this session (e.g. session2)\nCreate appropriate folders for code, data and anything else (e.g. images)\nCreate a script called learning-OD.R (or learning-OD.py if you are using python), e.g. with the following command:\n\nmkdir code\ncode code/learning-OD.R # for R\ncode code/learning-OD.py # for Python\n\n\n\n\nWe will start with a simple map of the world. Load the world object from the spData package. Notice the use of :: to say that you want the world object from the spData package.\n\nRPython\n\n\n\nworld = spData::world\n\n\n\n\nworld = gpd.read_file(\n    'https://naturalearth.s3.amazonaws.com/110m_cultural/ne_110m_admin_0_countries.zip'\n)\n\n\n\n\nUse some basic R functions to explore the world object. e.g. class(world), dim(world), head(world), summary(world). Also view the world object by clicking on it in the Environment panel.\nsf objects can be plotted with plot().\n\nRPython\n\n\n\nplot(world)\n\n\n\n\n\n\n\n\n\n\n\nprint(type(world))       # Equivalent to class(world)\nprint(world.shape)       # Equivalent to dim(world)\nprint(world.head())      # Equivalent to head(world)\nprint(world.describe())  # Equivalent to summary(world)\n\n# Plotting the world GeoDataFrame\nworld.plot(figsize=(12, 8))\nplt.title('World Map')\nplt.show()\n\n\n\n\nNote that this makes a map of each column in the data frame. Try some other plotting options\n\nRPython\n\n\n\nplot(world[3:6])\n\n\n\n\n\n\n\nplot(world[\"pop\"])\n\n\n\n\n\n\n\n\n\n\n\n# Since world is a GeoDataFrame, we can select columns by position\n# However, GeoPandas plots the geometry, so we need to specify columns\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\nworld.plot(column='POP_EST', ax=axes[0])\nworld.plot(column='GDP_YEAR', ax=axes[1])\nworld.plot(column='CONTINENT', ax=axes[2])\nplt.show()\n\n\n\n\n\n\n\nLoad the nz and nz_height datasets from the spData package.\n\nRPython\n\n\n\nnz = spData::nz\nnz_height = spData::nz_height\n\n\n\n\nnz = gpd.read_file(\"https://github.com/Nowosad/spData_files/raw/refs/heads/main/data/nz.gpkg\")\nnz_height = gpd.read_file(\"https://github.com/Nowosad/spData_files/raw/refs/heads/main/data/nz_height.gpkg\")\n\n\n\n\nWe can use tidyverse functions like filter and select on sf objects in the same way you did in Practical 1.\n\nRPython\n\n\n\ncanterbury = nz |&gt; filter(Name == \"Canterbury\")\ncanterbury_height = nz_height[canterbury, ]\n\n\n\n\ncanterbury = nz[nz['Name'] == 'Canterbury']\n\n\n\n\nIn this case we filtered the nz object to only include places called Canterbury and then did and intersection to find objects in the nz_height object that are in Canterbury.\nThis syntax is not very clear. But is the equivalent to\n\nRPython\n\n\n\ncanterbury_height = nz_height[canterbury, , op = st_intersects]\n\n\n\n\ncanterbury_height = gpd.overlay(nz_height, canterbury, how='intersection')\n\n\n\n\nThere are many different types of relationships you can use with op. Try ?st_intersects() to see more. For example this would give all the places not in Canterbury\n\nRPython\n\n\n\nnz_height[canterbury, , op = st_disjoint]\n\n\n\n\ncanterbury_height = gpd.sjoin(nz_height, canterbury, op='intersects')\n\n\n\n\n\n\n\nTopological relations between vector geometries, inspired by Figures 1 and 2 in Egenhofer and Herring (1990). The relations for which the function(x, y) is true are printed for each geometry pair, with x represented in pink and y represented in blue. The nature of the spatial relationship for each pair is described by the Dimensionally Extended 9-Intersection Model string."
  },
  {
    "objectID": "s2.html#pre-requisites",
    "href": "s2.html#pre-requisites",
    "title": "Origin-destination data analysis",
    "section": "",
    "text": "You need to have a number of packages installed and loaded. Install the packages by typing in the following commands into RStudio (you do not need to add the comments after the # symbol)\nIf you need to install any of these packages use:\n\nRPython\n\n\n\nif (!require(\"pak\")) install.packages(\"pak\")\npak::pkg_install(c(\"sf\", \"tidyverse\", \"remotes\", \"ggspatial\", \"tmap\"))\n\n\nlibrary(sf)        # vector data package\nlibrary(tidyverse) # tidyverse packages\nlibrary(ggspatial) # ggspatial package\nlibrary(spData)    # spatial data package\n\n\n\n\n# Install necessary packages (uncomment if not already installed)\n# !pip install geopandas pandas matplotlib seaborn\n\nimport geopandas as gpd       # vector data package\nimport pandas as pd           # data manipulation\nimport matplotlib.pyplot as plt  # plotting\nimport seaborn as sns            # advanced plotting\n# For spatial data, geopandas comes with sample datasets\n# Alternatively, we can use the naturalearth datasets\nimport geopandas.datasets\n\n\n\n\n\nCheck your packages are up-to-date with update.packages() in R (or equivalent in Python)\nCreate a project folder with an appropriate name for this session (e.g. session2)\nCreate appropriate folders for code, data and anything else (e.g. images)\nCreate a script called learning-OD.R (or learning-OD.py if you are using python), e.g. with the following command:\n\nmkdir code\ncode code/learning-OD.R # for R\ncode code/learning-OD.py # for Python"
  },
  {
    "objectID": "s2.html#basic-sf-operations",
    "href": "s2.html#basic-sf-operations",
    "title": "Origin-destination data analysis",
    "section": "",
    "text": "We will start with a simple map of the world. Load the world object from the spData package. Notice the use of :: to say that you want the world object from the spData package.\n\nRPython\n\n\n\nworld = spData::world\n\n\n\n\nworld = gpd.read_file(\n    'https://naturalearth.s3.amazonaws.com/110m_cultural/ne_110m_admin_0_countries.zip'\n)\n\n\n\n\nUse some basic R functions to explore the world object. e.g. class(world), dim(world), head(world), summary(world). Also view the world object by clicking on it in the Environment panel.\nsf objects can be plotted with plot().\n\nRPython\n\n\n\nplot(world)\n\n\n\n\n\n\n\n\n\n\n\nprint(type(world))       # Equivalent to class(world)\nprint(world.shape)       # Equivalent to dim(world)\nprint(world.head())      # Equivalent to head(world)\nprint(world.describe())  # Equivalent to summary(world)\n\n# Plotting the world GeoDataFrame\nworld.plot(figsize=(12, 8))\nplt.title('World Map')\nplt.show()\n\n\n\n\nNote that this makes a map of each column in the data frame. Try some other plotting options\n\nRPython\n\n\n\nplot(world[3:6])\n\n\n\n\n\n\n\nplot(world[\"pop\"])\n\n\n\n\n\n\n\n\n\n\n\n# Since world is a GeoDataFrame, we can select columns by position\n# However, GeoPandas plots the geometry, so we need to specify columns\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\nworld.plot(column='POP_EST', ax=axes[0])\nworld.plot(column='GDP_YEAR', ax=axes[1])\nworld.plot(column='CONTINENT', ax=axes[2])\nplt.show()"
  },
  {
    "objectID": "s2.html#basic-spatial-operations",
    "href": "s2.html#basic-spatial-operations",
    "title": "Origin-destination data analysis",
    "section": "",
    "text": "Load the nz and nz_height datasets from the spData package.\n\nRPython\n\n\n\nnz = spData::nz\nnz_height = spData::nz_height\n\n\n\n\nnz = gpd.read_file(\"https://github.com/Nowosad/spData_files/raw/refs/heads/main/data/nz.gpkg\")\nnz_height = gpd.read_file(\"https://github.com/Nowosad/spData_files/raw/refs/heads/main/data/nz_height.gpkg\")\n\n\n\n\nWe can use tidyverse functions like filter and select on sf objects in the same way you did in Practical 1.\n\nRPython\n\n\n\ncanterbury = nz |&gt; filter(Name == \"Canterbury\")\ncanterbury_height = nz_height[canterbury, ]\n\n\n\n\ncanterbury = nz[nz['Name'] == 'Canterbury']\n\n\n\n\nIn this case we filtered the nz object to only include places called Canterbury and then did and intersection to find objects in the nz_height object that are in Canterbury.\nThis syntax is not very clear. But is the equivalent to\n\nRPython\n\n\n\ncanterbury_height = nz_height[canterbury, , op = st_intersects]\n\n\n\n\ncanterbury_height = gpd.overlay(nz_height, canterbury, how='intersection')\n\n\n\n\nThere are many different types of relationships you can use with op. Try ?st_intersects() to see more. For example this would give all the places not in Canterbury\n\nRPython\n\n\n\nnz_height[canterbury, , op = st_disjoint]\n\n\n\n\ncanterbury_height = gpd.sjoin(nz_height, canterbury, op='intersects')\n\n\n\n\n\n\n\nTopological relations between vector geometries, inspired by Figures 1 and 2 in Egenhofer and Herring (1990). The relations for which the function(x, y) is true are printed for each geometry pair, with x represented in pink and y represented in blue. The nature of the spatial relationship for each pair is described by the Dimensionally Extended 9-Intersection Model string."
  },
  {
    "objectID": "next-steps.html",
    "href": "next-steps.html",
    "title": "1 Next Steps to Improve the Course Website",
    "section": "",
    "text": "The Quarto website for “Data Science for Transport Planning” has been successfully created with minimal placeholder content and rendered to the docs/ directory. The site is functional, but here are suggestions to enhance it:\n\n\n\nCreate an images/ directory and copy essential images from ../course/images/, such as icon.png for favicon and a logo (e.g., update tsrtr.png to a DSTP-specific logo).\nUncomment the favicon and logo lines in _quarto.yml once assets are added to avoid broken references.\n\n\n\n\n\nFill in session pages (s1.qmd to s8.qmd) with actual teaching materials adapted from ../course/ (e.g., s1.qmd: content on importing data using stats19, osmextract for Leeds).\nUpdate examples: adapt collisions.qmd and peoplemap.qmd for Leeds UK using local data (e.g., stats19 for West Yorkshire).\nEnhance materials.qmd with links to datasets, code repositories, and readings from dstp.qmd schedule.\n\n\n\n\n\nAdd hyperlinks in schedule.qmd to corresponding session pages, e.g., [Finding, importing and cleaning transport datasets](s1.qmd).\nEnsure session titles in s*.qmd match schedule exactly for consistency.\n\n\n\n\n\nVerify the R and Python test code in prerequisites.qmd runs without errors for Leeds (e.g., use execute_command to test Rscript -e \"source('prerequisites.R')\" if extracted).\nAdd screenshots or outputs for the test plots (e.g., Leeds road network visualization).\n\n\n\n\n\nCopy slides/ from ../course/ and adapt for DSTP topics (e.g., day1.qmd on introduction to data science).\nCopy data/ with Leeds-specific files (e.g., leeds_study_area.geojson generated from prerequisites).\nAdd references.bib copied from ../course/ and integrate citations in pages.\nCopy _extensions/ from ../course/ for custom Quarto features like bsicons.\n\n\n\n\n\nCommit changes and push to GitHub to trigger publish.yml for automatic deployment to gh-pages.\nTest the live site at https://tdscience.github.io/dstp/ and fix any broken links.\n\n\n\n\n\nAdd a forum link in sidebar if discussions are enabled on GitHub.\nInclude alignment with learning outcomes from dstp.qmd in index.qmd.\nAdd navigation to examples section and ensure mobile responsiveness.\nReview for accessibility and add alt text to future images.\n\nThese steps will transform the minimal site into a comprehensive course resource."
  },
  {
    "objectID": "next-steps.html#add-images-and-assets",
    "href": "next-steps.html#add-images-and-assets",
    "title": "1 Next Steps to Improve the Course Website",
    "section": "",
    "text": "Create an images/ directory and copy essential images from ../course/images/, such as icon.png for favicon and a logo (e.g., update tsrtr.png to a DSTP-specific logo).\nUncomment the favicon and logo lines in _quarto.yml once assets are added to avoid broken references."
  },
  {
    "objectID": "next-steps.html#expand-placeholder-content",
    "href": "next-steps.html#expand-placeholder-content",
    "title": "1 Next Steps to Improve the Course Website",
    "section": "",
    "text": "Fill in session pages (s1.qmd to s8.qmd) with actual teaching materials adapted from ../course/ (e.g., s1.qmd: content on importing data using stats19, osmextract for Leeds).\nUpdate examples: adapt collisions.qmd and peoplemap.qmd for Leeds UK using local data (e.g., stats19 for West Yorkshire).\nEnhance materials.qmd with links to datasets, code repositories, and readings from dstp.qmd schedule."
  },
  {
    "objectID": "next-steps.html#integrate-schedule-links",
    "href": "next-steps.html#integrate-schedule-links",
    "title": "1 Next Steps to Improve the Course Website",
    "section": "",
    "text": "Add hyperlinks in schedule.qmd to corresponding session pages, e.g., [Finding, importing and cleaning transport datasets](s1.qmd).\nEnsure session titles in s*.qmd match schedule exactly for consistency."
  },
  {
    "objectID": "next-steps.html#test-and-refine-prerequisites",
    "href": "next-steps.html#test-and-refine-prerequisites",
    "title": "1 Next Steps to Improve the Course Website",
    "section": "",
    "text": "Verify the R and Python test code in prerequisites.qmd runs without errors for Leeds (e.g., use execute_command to test Rscript -e \"source('prerequisites.R')\" if extracted).\nAdd screenshots or outputs for the test plots (e.g., Leeds road network visualization)."
  },
  {
    "objectID": "next-steps.html#add-supporting-directories-and-files",
    "href": "next-steps.html#add-supporting-directories-and-files",
    "title": "1 Next Steps to Improve the Course Website",
    "section": "",
    "text": "Copy slides/ from ../course/ and adapt for DSTP topics (e.g., day1.qmd on introduction to data science).\nCopy data/ with Leeds-specific files (e.g., leeds_study_area.geojson generated from prerequisites).\nAdd references.bib copied from ../course/ and integrate citations in pages.\nCopy _extensions/ from ../course/ for custom Quarto features like bsicons."
  },
  {
    "objectID": "next-steps.html#deployment-and-cicd",
    "href": "next-steps.html#deployment-and-cicd",
    "title": "1 Next Steps to Improve the Course Website",
    "section": "",
    "text": "Commit changes and push to GitHub to trigger publish.yml for automatic deployment to gh-pages.\nTest the live site at https://tdscience.github.io/dstp/ and fix any broken links."
  },
  {
    "objectID": "next-steps.html#additional-improvements",
    "href": "next-steps.html#additional-improvements",
    "title": "1 Next Steps to Improve the Course Website",
    "section": "",
    "text": "Add a forum link in sidebar if discussions are enabled on GitHub.\nInclude alignment with learning outcomes from dstp.qmd in index.qmd.\nAdd navigation to examples section and ensure mobile responsiveness.\nReview for accessibility and add alt text to future images.\n\nThese steps will transform the minimal site into a comprehensive course resource."
  },
  {
    "objectID": "s1.html",
    "href": "s1.html",
    "title": "Finding, importing and cleaning transport datasets",
    "section": "",
    "text": "Placeholder for session 1 content.\n\n\n\nReuseCC BY-SA 4.0Copyright© 2025 Robin Lovelace"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Time\nSession\n\n\n\n\n\n10:00 - 11:00\nIntroduction to Data Science for Transport Planning\n\n\n\n11:00 - 12:30\nFinding, importing and cleaning transport datasets- Origin-destination datasets- OpenStreetMap (OSM) and Ordnance Survey (OS) OpenRoads datasets- Stats19 road safety data\n\n\n\n12:30 - 13:30\nLunch\n\n\n\n13:30 - 15:00\nOrigin-destination data analysis\n\n\n\n15:00 - 15:15\nBreak and refreshments\n\n\n\n15:15 - 17:00\nOD Transport data visualisation",
    "crumbs": [
      "Schedule"
    ]
  },
  {
    "objectID": "schedule.html#day-1-introduction-to-rrstudio",
    "href": "schedule.html#day-1-introduction-to-rrstudio",
    "title": "Schedule",
    "section": "",
    "text": "Time\nSession\n\n\n\n\n\n10:00 - 11:00\nIntroduction to Data Science for Transport Planning\n\n\n\n11:00 - 12:30\nFinding, importing and cleaning transport datasets- Origin-destination datasets- OpenStreetMap (OSM) and Ordnance Survey (OS) OpenRoads datasets- Stats19 road safety data\n\n\n\n12:30 - 13:30\nLunch\n\n\n\n13:30 - 15:00\nOrigin-destination data analysis\n\n\n\n15:00 - 15:15\nBreak and refreshments\n\n\n\n15:15 - 17:00\nOD Transport data visualisation",
    "crumbs": [
      "Schedule"
    ]
  },
  {
    "objectID": "schedule.html#day-2",
    "href": "schedule.html#day-2",
    "title": "Schedule",
    "section": "2 Day 2",
    "text": "2 Day 2\n\n\n\n\n\n\n\n\nTime\nSession\n\n\n\n\n\n09:00 - 10:45\nSpatio-temporal data- Demonstration of open-access OD data with hourly resolution- Demonstration with stats19 data for road safety analysis\n\n\n\n10:45 - 11:15\nBreak and refreshments\n\n\n\n11:15 - 12:30\nRouting and route network analysis- Setting up an interface to a routing engine and using it to calculate routes and distances using GTFS data\n\n\n\n12:30 - 13:30\nLunch\n\n\n\n13:30 - 15:00\nBest practices for data science in transport planning- Version control with Git and GitHub- Reproducible research with Quarto\n\n\n\n15:00 - 16:00\nAdvanced topics- Visualising large datasets- Route network integration (e.g., OSM networks)- Deploying your work as web applications",
    "crumbs": [
      "Schedule"
    ]
  },
  {
    "objectID": "s7.html",
    "href": "s7.html",
    "title": "Advanced topics",
    "section": "",
    "text": "Placeholder for session 7 content.\n\n\n\nReuseCC BY-SA 4.0Copyright© 2025 Robin Lovelace"
  },
  {
    "objectID": "s4.html",
    "href": "s4.html",
    "title": "Spatio-temporal data",
    "section": "",
    "text": "Placeholder for session 4 content.\n\n\n\nReuseCC BY-SA 4.0Copyright© 2025 Robin Lovelace"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science for Transport Planning: 2 day course",
    "section": "",
    "text": "Get yours at store.leeds.ac.uk {-}",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#note-tickets-are-now-on-sale",
    "href": "index.html#note-tickets-are-now-on-sale",
    "title": "Data Science for Transport Planning: 2 day course",
    "section": "",
    "text": "Get yours at store.leeds.ac.uk {-}",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#course-overview",
    "href": "index.html#course-overview",
    "title": "Data Science for Transport Planning: 2 day course",
    "section": "2 Course Overview",
    "text": "2 Course Overview\nBased on demand, we’re organising a 2-day course teaching modern data science skills for transport planning, focussed on transport planning practitioners.\nThis course will take place on the 18th and 19th of September 2025 at the University of Leeds.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#learning-objectives",
    "href": "index.html#learning-objectives",
    "title": "Data Science for Transport Planning: 2 day course",
    "section": "3 Learning Objectives",
    "text": "3 Learning Objectives\n\nUnderstand the role of data science in transport planning.\nLearn how to find, import, clean, and analyze transport data.\nDevelop skills in data visualization and reporting.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "Data Science for Transport Planning: 2 day course",
    "section": "4 Prerequisites",
    "text": "4 Prerequisites\n\nExperience with transport planning concepts and datasets, such as origin-destination data and route networks.\nBasic programming skills in R, Python or similar.\nA laptop with R and RStudio (recommended) or a Python distribution such as Anaconda and an editor such as VS Code or Jupyter Notebook set-up.\n\nSee the prerequisites page for details and to test your setup.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Data Science for Transport Planning: 2 day course",
    "section": "5 Schedule",
    "text": "5 Schedule\nSee the schedule page for the detailed schedule.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#registration",
    "href": "index.html#registration",
    "title": "Data Science for Transport Planning: 2 day course",
    "section": "6 Registration",
    "text": "6 Registration\nSee store.leeds.ac.uk for registration details.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Data Science for Transport Planning: 2 day course",
    "section": "7 Contact",
    "text": "7 Contact\nFor inquiries, please contact Robin Lovelace.\nWe look forward to seeing you at the course!",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "s3.html",
    "href": "s3.html",
    "title": "OD Transport data visualisation",
    "section": "",
    "text": "1 Introduction\nIn this session, we will build on the routing techniques from Session 3 by exploring data visualisation methods for transport analysis. By the end of this practical, you should be able to:\n\nLoad and preprocess OD flow data\nVisualise OD lines and proportional symbol maps\nCompare walking, driving, and cycling flows\nAggregate flows along the road network\nIdentify critical road segments via network centrality\n\n\n\n2 Setup\nBelow are the libraries we will use throughout this practical:\n\nknitr::opts_chunk$set(\n  message = FALSE,\n  warning = FALSE,\n  fig.width = 7,\n  fig.height = 5,\n  out.width = \"700px\"\n)\n\n# Load necessary libraries\nlibrary(opentripplanner)  # Routing engine (OpenTripPlanner client)\nlibrary(sf)               # Spatial data handling\nlibrary(tmap)             # Thematic mapping\nlibrary(stplanr)          # Transport data functions\nlibrary(dplyr)            # Data manipulation\nlibrary(osmextract)       # OSM data handling\nlibrary(dodgr)            # Network analysis\n\n\n# Set interactive mapping mode\ntmap_mode(\"view\")\n\n\n\n3 Flow Map Visualization\nFlow maps are useful for understanding the volume of travel between origins and destinations. In this section, we will:\n\nLoad desire lines (flows) data from a GeoJSON file.\nVisualize these lines with widths or colors proportional to demand.\nOptionally aggregate route geometries for more realistic depiction of flows along an actual road network.\n\n\n# Load Demand Data\ndesire_lines = read_sf(\"https://github.com/ITSLeeds/TDS/releases/download/22/NTEM_flow.geojson\") |&gt;\n  select(from, to, all, walk, drive, cycle)\n\ndim(desire_lines)\n\n[1] 502   7\n\n# Let's take the top 50 car trips for demonstration\ndesire_lines_top = desire_lines |&gt;\n  arrange(desc(drive)) |&gt;\n  head(50)\n\n# Quick map to see the distribution of car trips\ntm_shape(desire_lines_top) +\n  tm_lines(\n    lwd = \"drive\",\n    lwd.scale = tm_scale_continuous(values.scale = 9)\n  ) +\n  tm_layout(legend.bg.color = \"white\")\n\n\n\n\n\n\n\n\n4 Proportional Symbol Flow Maps\nNow, let’s illustrate an alternative method: proportional symbols at origin or destination points. This is useful when you want to quickly see where demand is concentrated.\n\n# Summarize total flows by origin\n\norigin_flows = desire_lines |&gt;\n  group_by(from) |&gt;\n  summarise(\n    total_drive = sum(drive, na.rm = TRUE),\n    total_walk  = sum(walk, na.rm = TRUE),\n    total_cycle = sum(cycle, na.rm = TRUE),\n    `% drive` = total_drive / sum(all, na.rm = TRUE),\n    geometry = st_centroid(st_union(geometry))  \n  )\n\n# Simple map with proportional circles for drive volumes\n\ntm_shape(origin_flows) +\n  tm_bubbles(\n    size    = \"total_drive\",       # bubble size ~ drive volume\n    size.scale = tm_scale_intervals(values.scale = 2, values.range = c(0.5, 2)),\n    fill = \"% drive\",\n    fill.scale = tm_scale_continuous(values = \"brewer.reds\")\n  ) +\n  tm_title(\"Proportional Symbol Map of Drive Demand by Origin\")\n\n\n\n\n\n\n\nEach origin is represented by a circle whose radius and color intensity reflect the total number of driving trips. You can modify palettes, breaks, and scaling to highlight variations.\n\n\n5 Mode-Specific Analysis\nWe have have columns walk, drive, cycle in desire_lines. We can map them separately or side-by-side. We can also color lines by the dominant mode.\n\n# Let's create 3 separate maps: drive, walk, cycle\ntmap_mode(\"plot\")\nm_drive = tm_shape(desire_lines_top) +\n  tm_lines(\n    lwd = \"drive\",\n    lwd.scale = tm_scale_continuous(values.scale = 9),\n    col = \"red\"\n  ) +\n  tm_title(\"Driving Flows\")\n\nm_walk = tm_shape(desire_lines_top) +\n  tm_lines(\n    lwd = \"walk\",\n    lwd.scale = tm_scale_continuous(values.scale = 9),\n    col = \"green\"\n  ) +\n  tm_title(\"Walking Flows\")\n\nm_cycle = tm_shape(desire_lines_top) +\n  tm_lines(\n    lwd = \"cycle\",\n    lwd.scale = tm_scale_continuous(values.scale = 9),\n    col = \"blue\"\n  ) +\n  tm_title(\"Cycling Flows\")\n\ntmap_arrange(m_drive, m_walk, m_cycle, ncol=3)\n\n\n\n\n\n\n\n\nThis tmap_arrange() will output a single figure with three columns, each illustrating flows by one mode. Students can visually compare the differences: maybe driving flows are much thicker on longer corridors, while walking flows are concentrated in the city center.\n\n\n6 Aggregating Flows with Actual Routes\nRather than drawing direct origin-destination lines, we can route each flow along the road network and then aggregate them to see which streets carry the most traffic. This uses stplanr::overline() to merge lines that overlap.\n\n# Download pre-routed lines for demonstration\nu = \"https://github.com/ITSLeeds/TDS/releases/download/22/routes_drive_25.geojson\"\nroutes_drive = read_sf(u)\n\n# Inspect the summary of the drive.x variable (car trips)\nsummary(routes_drive$drive.x)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   41.0   171.2   327.0   415.1   546.5  2346.0 \n\ntm_shape(routes_drive) +\n  tm_lines(\n    lwd = \"drive.x\",\n    lwd.scale = tm_scale_continuous(values.scale = 9),\n    col = \"red\"\n  ) +\n  tm_title(\"Road Congestion (drive_total)\")\n\n\n\n\n\n\n\n\n\n\n7 Network Centrality Analysis\nBetweenness centrality indicates how often a road (or node) lies on the shortest path between other points in a network. Roads with high centrality are typically crucial for overall connectivity.\nHere, we demonstrate how to:\n\nDownload roads from OpenStreetMap (OSM) for the Isle of Wight.\nWeight the network for motor vehicle usage.\nCompute betweenness centrality with dodgr.\nConvert the results back to sf for mapping.\n\n\n# Get Isle of Wight road network\n# We choose 'primary', 'secondary', 'tertiary' roads for demonstration\nroads = oe_get(\"Isle of Wight\", \n                extra_tags = c(\"maxspeed\", \"oneway\")) |&gt;\n  filter(highway %in% c(\"primary\", \"secondary\", \"tertiary\"))\n\n# Weight the street network for motorcar usage\ngraph = weight_streetnet(\n  roads,\n  wt_profile = \"motorcar\",\n  type_col = \"highway\",\n  id_col = \"osm_id\",\n  keep_cols = c(\"maxspeed\", \"oneway\")\n)\n\n# Calculate betweenness centrality\ncentrality = dodgr_centrality(graph)\n\n# Convert to sf for visualization\ncentrality_sf = dodgr_to_sf(centrality)\n\n# Visualize critical links\ntm_shape(centrality_sf) +\n  tm_lines(\n    col = \"centrality\",\n    col.scale = tm_scale_intervals(style = \"fisher\", values = \"-viridis\"),\n    col.legend = tm_legend(title = \"Betweenness Centrality\"),\n    lwd = 3\n  ) \n\nThe code above should generate a map that looks something like this:\n\nHigh values in the centrality column indicate roads that act as vital connectors in the regional transport network.\n\n\n8 Extra Exercises: 3D Visualization\nA 3D perspective can often reveal relationships between travel flows and the underlying topography more effectively. Below, we demonstrate how to retrieve elevation data and render a 3D hillshade using the rayshader package. You may also be interested in overlaying flow lines onto a 3D terrain model to enhance visualization.\nNote: the following code requires you to install the rayshader elevatr gifski rgl package. Results not shown in website.\n\nlibrary(rayshader)        # 3D data visualization\nlibrary(elevatr)          # Elevation data\nlibrary(gifski)           # Creating GIF animations\nlibrary(rgl)              # 3D visualization device\n\nassign(\"has_internet_via_proxy\", TRUE, environment(curl::has_internet))\ncurl::has_internet()\n# Example: Elevation data near a location in the UK\ncoords = data.frame(x = -2.087918, y = 53.71534)\ncoords_sf = st_as_sf(coords, coords = c(\"x\", \"y\"), crs = 4326)\n# Get an elevation raster at zoom level 11 (~ 10m resolution, depending on region)\nelevation = elevatr::get_elev_raster(\n  locations = coords_sf,\n  z = 11\n)\n# Convert the raster to a matrix for rayshader\nelev_matrix = rayshader::raster_to_matrix(elevation)\n# Create a hillshade layer\nhillshade_matrix = rayshader::ray_shade(elev_matrix, zscale = 15)\n# Clear existing rgl device\nrgl::rgl.clear()\n# Render a 3D plot of the terrain\nrayshader::plot_3d(\n  heightmap = elev_matrix,\n  hillshade = hillshade_matrix,\n  zscale = 15,\n  windowsize = c(1000, 800)\n)\n# Adjust camera view\nrgl::view3d(theta = 30, phi = 30, zoom = 0.75)\nrgl::rglwidget()\n\n\n\n9 Conclusions\nIn this practical, you learned how to:\n\nCreate flow maps to visualize travel demand from an OD dataset.\nCompare flows by mode (driving, walking, cycling) to understand differences in spatial patterns.\nAggregate routes along the road network (using stplanr::overline) to highlight heavily used corridors.\nCompute betweenness centrality (using dodgr) to pinpoint critical road segments crucial for connectivity.\n\n\n\n\n\nReuseCC BY-SA 4.0Copyright© 2025 Robin Lovelace"
  }
]