[
  {
    "objectID": "prerequisites.html",
    "href": "prerequisites.html",
    "title": "Prerequisites",
    "section": "",
    "text": "This course assumes working knowledge with R or Python for research. We assume that you are already comfortable with an integrated development environment (IDE), such as RStudio or VS Code. You must have a GitHub account and it will be beneficial to be familiar with the concepts of version control, although we will cover these in the course.\nFamiliarity with referencing software such as Zotero (recommended) and bibliography file formats such as BibTeX will be beneficial, but not essential.",
    "crumbs": [
      "Prerequisites"
    ]
  },
  {
    "objectID": "prerequisites.html#course-prerequisites",
    "href": "prerequisites.html#course-prerequisites",
    "title": "Prerequisites",
    "section": "",
    "text": "This course assumes working knowledge with R or Python for research. We assume that you are already comfortable with an integrated development environment (IDE), such as RStudio or VS Code. You must have a GitHub account and it will be beneficial to be familiar with the concepts of version control, although we will cover these in the course.\nFamiliarity with referencing software such as Zotero (recommended) and bibliography file formats such as BibTeX will be beneficial, but not essential.",
    "crumbs": [
      "Prerequisites"
    ]
  },
  {
    "objectID": "prerequisites.html#software-prerequisites",
    "href": "prerequisites.html#software-prerequisites",
    "title": "Prerequisites",
    "section": "2 Software Prerequisites",
    "text": "2 Software Prerequisites\nYou should bring a laptop with the following software installed and tested to check it works:\n\nQuarto (minimum version: 1.5.45)\nA tested R or Python installation or both (note: if you have Docker installed you should be able to run R and Python inside a devcontainer, works best with VS Code)\nRStudio or VS Code IDE\n\nIf you use RStudio, it should ‘just work’ with R and Quarto.\nIf you will use VS Code for the course, you need the following extensions:\n\nThe R extension reditorsupport.r if using R\nThe Python extension ms-python.python if using Python\nThe quarto extention quarto.quarto\n\nFor experienced users: you can also use an IDE of your choice, for example Positron IDE which is based on VS Code and has R, Python and Quarto support built-in.\n\nGit, installed with one of the following packages:\n\nGitHub Desktop (see desktop.github.com)\nGit for the command line (see git-scm.com)\n\nThe gh command-line tool (see cli.github.com for installation and set-up instructions)",
    "crumbs": [
      "Prerequisites"
    ]
  },
  {
    "objectID": "prerequisites.html#recommended-online-courses",
    "href": "prerequisites.html#recommended-online-courses",
    "title": "Prerequisites",
    "section": "3 Recommended Online Courses",
    "text": "3 Recommended Online Courses\nStudents should take these short but very useful online courses to prepare:\n\nIntro to GitHub (should take less than an hour)\nCommunicate using Markdown (should take around 30 minutes or less)",
    "crumbs": [
      "Prerequisites"
    ]
  },
  {
    "objectID": "prerequisites.html#testing-your-setup",
    "href": "prerequisites.html#testing-your-setup",
    "title": "Prerequisites",
    "section": "4 Testing your setup",
    "text": "4 Testing your setup\nYou can test your setup by running the following code in R or Python.\n\nRPython\n\n\n\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!require(\"pak\")) install.packages(\"pak\")\npkgs = c(\n    \"sf\",\n    \"tidyverse\",\n    \"tmap\",\n    \"stats19\",\n    \"stplanr\",\n    \"osmextract\",\n    \"zonebuilder\"\n)\npak::pak(pkgs)\nlibrary(tidyverse)\nzones = zonebuilder::zb_zone(\"Leeds\", n_circles = 3)\nstudy_area = zones |&gt;\n  sf::st_union()\nextra_tags = c(\n  \"maxspeed\",\n  \"lit\",\n  \"cycleway\"\n)\nosm_network = osmextract::oe_get(\n  place = study_area,\n  boundary = study_area,\n  boundary_type = \"clipsrc\",\n  extra_tags = extra_tags\n)\n\n\nosm_network |&gt;\n  select(maxspeed) |&gt;\n  plot()\n\n\n\n\n\n\n\nsf::write_sf(study_area, \"leeds_study_area.geojson\")\n\n\n\n\nimport osmnx as ox\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport shapely\n\nstudy_point = shapely.Point(-1.55, 53.80)  # Latitude and Longitude for Leeds\nstudy_geom = gpd.GeoSeries([study_point], crs=4326)\nstudy_polygon = study_geom.to_crs(epsg=3857).buffer(6000).to_crs(epsg=4326).unary_union\nstudy_polygon_gpd = gpd.GeoDataFrame(geometry=[study_polygon], crs=\"EPSG:4326\")\n# Read-in geojson already saved from R\nstudy_polygon = gpd.read_file(\"leeds_study_area.geojson\")\n# study_polygon_gpd.explore()\ntags = {\"highway\": True, \"maxspeed\": True, \"lit\": True, \"cycleway\": True}\ngdf = ox.features_from_polygon(study_polygon, tags)\ngdf = gdf[gdf.geom_type.isin([\"LineString\", \"MultiLineString\"])]\ngdf = gdf.to_crs(epsg=3857)\ngdf.plot(column=\"maxspeed\", figsize=(10, 10), legend=True)\nplt.show()\n\n\n\n\nLet us know how you get on and let us know if you have any issues getting set up, either by email, or (preferably) via the Discussion forum on GitHub associated with this course repository at github.com/tdscience/dstp/discussions.",
    "crumbs": [
      "Prerequisites"
    ]
  },
  {
    "objectID": "slides/day2.html#welcome-to-day-2",
    "href": "slides/day2.html#welcome-to-day-2",
    "title": "Data Science for Transport Planning: Day 2",
    "section": "Welcome to Day 2!",
    "text": "Welcome to Day 2!\nData Science for Transport Planning\n2-day course\n18-19 September 2025"
  },
  {
    "objectID": "slides/day2.html#agenda",
    "href": "slides/day2.html#agenda",
    "title": "Data Science for Transport Planning: Day 2",
    "section": "Agenda",
    "text": "Agenda\n\n09:00-10:45 Spatio-temporal data\n10:45-11:15 Break and refreshments\n11:15-12:30 Routing and route network analysis\n12:30-13:30 Lunch\n13:30-15:00 Best practices for data science in transport planning\n15:00-16:00 Advanced topics"
  },
  {
    "objectID": "slides/day2.html#recap-of-day-1",
    "href": "slides/day2.html#recap-of-day-1",
    "title": "Data Science for Transport Planning: Day 2",
    "section": "Recap of Day 1",
    "text": "Recap of Day 1\n\nIntroduction to Data Science for Transport Planning\nFinding, importing and cleaning transport datasets\nOrigin-destination data analysis\nOD Transport data visualisation"
  },
  {
    "objectID": "slides/day2.html#lets-move-to-the-practical-sessions",
    "href": "slides/day2.html#lets-move-to-the-practical-sessions",
    "title": "Data Science for Transport Planning: Day 2",
    "section": "Let’s move to the practical sessions",
    "text": "Let’s move to the practical sessions\nSee the schedule for details.\nAny questions before we start?"
  },
  {
    "objectID": "session1.html",
    "href": "session1.html",
    "title": "1 Importing data from OSM",
    "section": "",
    "text": "1 Importing data from OSM\n\n# Code goes here\n\n\n\n\n\nReuseCC BY-SA 4.0Copyright© 2025 Robin Lovelace"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science for Transport Planning",
    "section": "",
    "text": "Open in GitHub Codespaces\n\n\nNote: Tickets are now sold out\n\n\n\nUnderstand the role of data science in transport planning.\nLearn how to find, import, clean, and analyze transport data.\nDevelop skills in data visualization and reporting.\n\n\n\n\nSee store.leeds.ac.uk for registration details.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#learning-objectives",
    "href": "index.html#learning-objectives",
    "title": "Data Science for Transport Planning",
    "section": "",
    "text": "Understand the role of data science in transport planning.\nLearn how to find, import, clean, and analyze transport data.\nDevelop skills in data visualization and reporting.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#registration",
    "href": "index.html#registration",
    "title": "Data Science for Transport Planning",
    "section": "",
    "text": "See store.leeds.ac.uk for registration details.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#course-overview",
    "href": "index.html#course-overview",
    "title": "Data Science for Transport Planning",
    "section": "Course Overview",
    "text": "Course Overview\nThis course teaches modern data science skills tailored for transport planning, including data acquisition, cleaning, analysis, visualization, and reproducible reporting. It focuses on practical applications using R and Python, with real-world transport datasets.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "Data Science for Transport Planning",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nBasic knowledge of transport planning concepts and datasets\nFamiliarity with programming in R or Python\nA laptop with R (essential), Python (optional) and a data science IDE such as RStudio (recommended), VS Code or Positron installed\nA GitHub account (a GitHub account should allow you to run the code in the cloud via GitHub Codespaces as a fallback if needed)\n\nSee the prerequisites page for detailed setup instructions.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Data Science for Transport Planning",
    "section": "Schedule",
    "text": "Schedule\nThe course covers 7 sessions over 2 days. See the schedule page for details.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#technical-information",
    "href": "index.html#technical-information",
    "title": "Data Science for Transport Planning",
    "section": "Technical Information",
    "text": "Technical Information\n\nThe repository structure is as follows:\n\ns1.qmd to s7.qmd: Course session materials\ndata/: Sample datasets used in the course\ntds/: Additional transport data science materials and projects\n.devcontainer/: DevContainer configuration for consistent development environment\n.github/: GitHub Actions workflows for publishing\n\n\nRunning Locally\nThis project uses Quarto to generate the website. To run locally:\n\nInstall Quarto: https://quarto.org/docs/get-started/\nClone this repository\nOpen in VS Code with DevContainer support (recommended)\nRun quarto preview to preview the site\n\nAlternatively, use the “Open in Codespaces” button above for an instant cloud development environment.\n\n\nContributing\nContributions are welcome! Please:\n\nOpen issues for bugs or feature requests\nSubmit pull requests for improvements\nJoin the GitHub Discussions for questions",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Data Science for Transport Planning",
    "section": "License",
    "text": "License\nThis project is licensed under CC BY-SA 4.0. See LICENSE for details.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Data Science for Transport Planning",
    "section": "Contact",
    "text": "Contact\nFor course inquiries: Robin Lovelace\nRepository maintainer: Robin Lovelace",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "s4.html",
    "href": "s4.html",
    "title": "Spatio-temporal data",
    "section": "",
    "text": "Placeholder for session 4 content.\n\n\n\nReuseCC BY-SA 4.0Copyright© 2025 Robin Lovelace"
  },
  {
    "objectID": "s7.html",
    "href": "s7.html",
    "title": "Advanced topics",
    "section": "",
    "text": "Placeholder for session 7 content.\n\n\n\nReuseCC BY-SA 4.0Copyright© 2025 Robin Lovelace"
  },
  {
    "objectID": "s2.html",
    "href": "s2.html",
    "title": "Origin-destination data analysis",
    "section": "",
    "text": "Origin-destination (OD) data forms the backbone of transportation planning, urban analytics, and spatial mobility research. This type of data captures movement patterns between geographic locations, revealing how people, goods, or services flow through space. Understanding OD data is crucial for making informed decisions such as infrastructure development and public transport planning.\nIn this session, we will how to use and analyse geographic and origin-destination data. It includes:\n\nA short lecture on geographic and origin-destination data (see slides)\nHands-on analysis: Working with various geographic and OD datasets\n\n\n\nYou need to have a number of packages installed and loaded. Install the packages by typing in the following commands into RStudio (you do not need to add the comments after the # symbol)\nIf you need to install any of these packages use:\n\nRPython\n\n\n\nif (!require(\"pak\")) install.packages(\"pak\")\npak::pkg_install(c(\"sf\", \"tidyverse\", \"ggspatial\", \"tmap\"))\n\n\nlibrary(sf)        # vector data package\nlibrary(tidyverse) # tidyverse packages\nlibrary(ggspatial) # ggspatial package\nlibrary(spData)    # spatial data package\n\n\n\n\n# Install necessary packages (uncomment if not already installed)\n# !pip install geopandas pandas matplotlib seaborn\nimport geopandas as gpd       # vector data package\nimport pandas as pd           # data manipulation\nimport matplotlib.pyplot as plt  # plotting\nimport seaborn as sns            # advanced plotting\n# For spatial data, geopandas comes with sample datasets\n# Alternatively, we can use the naturalearth datasets\nimport geopandas.datasets\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote: this session assumes you have run the code in the prerequisites and Session 1 workbooks.\nEnsure you have set-up a project folder and have that open in RStudio or VS Code, as described in Session 1.\n\n\n\nCheck your packages are up-to-date with update.packages() in R (or equivalent in Python)\nCreate appropriate folders for code, data and anything else (e.g. images)\nCreate a script called learning-OD.R (or learning-OD.py if you are using python), e.g. with the following command:\n\nmkdir code\ncode code/learning-OD.R # for R\ncode code/learning-OD.py # for Python\n\n\n\n\nWe will start with a simple map of the world. Load the world object from the spData package. Notice the use of :: to say that you want the world object from the spData package.\n\nRPython\n\n\n\nworld = spData::world\n\n\n\n\nworld = gpd.read_file(\n    'https://naturalearth.s3.amazonaws.com/110m_cultural/ne_110m_admin_0_countries.zip'\n)\n\n\n\n\nUse some basic R functions to explore the world object. e.g. class(world), dim(world), head(world), summary(world). Also view the world object by clicking on it in the Environment panel.\nsf objects can be plotted with plot().\n\nRPython\n\n\n\nplot(world)\n\n\n\n\n\n\n\n\n\n\n\nworld = gpd.read_file(\n    'https://naturalearth.s3.amazonaws.com/110m_cultural/ne_110m_admin_0_countries.zip'\n)\nprint(type(world))       # Equivalent to class(world)\nprint(world.shape)       # Equivalent to dim(world)\nprint(world.head())      # Equivalent to head(world)\nprint(world.describe())  # Equivalent to summary(world)\n\n# Plotting the world GeoDataFrame\nworld.plot(figsize=(12, 8))\nplt.title('World Map')\nplt.show()\n\n\n\n\nNote that this makes a map of each column in the data frame. Try some other plotting options\n\nRPython\n\n\n\nworld = spData::world\nplot(world[3:6])\n\n\n\n\n\n\n\nplot(world[\"pop\"])\n\n\n\n\n\n\n\n\n\n\n\n# Since world is a GeoDataFrame, we can select columns by position\n# However, GeoPandas plots the geometry, so we need to specify columns\nworld = gpd.read_file('https://naturalearth.s3.amazonaws.com/110m_cultural/ne_110m_admin_0_countries.zip')\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\nworld.plot(column='POP_EST', ax=axes[0])\nworld.plot(column='GDP_YEAR', ax=axes[1])\nworld.plot(column='CONTINENT', ax=axes[2])\nplt.show()\n\n\n\n\n\n\n\n\nLoad the nz and nz_height datasets from the spData package.\n\nRPython\n\n\n\nnz = spData::nz\nnz_height = spData::nz_height\n\n\n\n\nnz = gpd.read_file(\"https://github.com/Nowosad/spData_files/raw/refs/heads/main/data/nz.gpkg\")\nnz_height = gpd.read_file(\"https://github.com/Nowosad/spData_files/raw/refs/heads/main/data/nz_height.gpkg\")\n\n\n\n\nWe can use tidyverse functions like filter and select on sf objects in the same way you did in Practical 1.\n\nRPython\n\n\n\ncanterbury = nz |&gt; filter(Name == \"Canterbury\")\ncanterbury_height = nz_height[canterbury, ]\n\n\n\n\ncanterbury = nz[nz['Name'] == 'Canterbury']\n\n\n\n\nIn this case we filtered the nz object to only include places called Canterbury and then did and intersection to find objects in the nz_height object that are in Canterbury.\nThis syntax is not very clear. But is the equivalent to\n\nRPython\n\n\n\ncanterbury_height = nz_height[canterbury, , op = st_intersects]\n\n\n\n\ncanterbury_height = gpd.overlay(nz_height, canterbury, how='intersection')\n\n\n\n\nThere are many different types of relationships you can use with op. Try ?st_intersects() to see more. For example this would give all the places not in Canterbury\n\nRPython\n\n\n\nnz_height[canterbury, , op = st_disjoint]\n\n\n\n\ncanterbury_height = gpd.sjoin(nz_height, canterbury, op='intersects')\n\n\n\n\n\n\n\nTopological relations between vector geometries, inspired by Figures 1 and 2 in Egenhofer and Herring (1990). The relations for which the function(x, y) is true are printed for each geometry pair, with x represented in pink and y represented in blue. The nature of the spatial relationship for each pair is described by the Dimensionally Extended 9-Intersection Model string."
  },
  {
    "objectID": "s2.html#pre-requisites",
    "href": "s2.html#pre-requisites",
    "title": "Origin-destination data analysis",
    "section": "",
    "text": "You need to have a number of packages installed and loaded. Install the packages by typing in the following commands into RStudio (you do not need to add the comments after the # symbol)\nIf you need to install any of these packages use:\n\nRPython\n\n\n\nif (!require(\"pak\")) install.packages(\"pak\")\npak::pkg_install(c(\"sf\", \"tidyverse\", \"ggspatial\", \"tmap\"))\n\n\nlibrary(sf)        # vector data package\nlibrary(tidyverse) # tidyverse packages\nlibrary(ggspatial) # ggspatial package\nlibrary(spData)    # spatial data package\n\n\n\n\n# Install necessary packages (uncomment if not already installed)\n# !pip install geopandas pandas matplotlib seaborn\nimport geopandas as gpd       # vector data package\nimport pandas as pd           # data manipulation\nimport matplotlib.pyplot as plt  # plotting\nimport seaborn as sns            # advanced plotting\n# For spatial data, geopandas comes with sample datasets\n# Alternatively, we can use the naturalearth datasets\nimport geopandas.datasets\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote: this session assumes you have run the code in the prerequisites and Session 1 workbooks.\nEnsure you have set-up a project folder and have that open in RStudio or VS Code, as described in Session 1.\n\n\n\nCheck your packages are up-to-date with update.packages() in R (or equivalent in Python)\nCreate appropriate folders for code, data and anything else (e.g. images)\nCreate a script called learning-OD.R (or learning-OD.py if you are using python), e.g. with the following command:\n\nmkdir code\ncode code/learning-OD.R # for R\ncode code/learning-OD.py # for Python"
  },
  {
    "objectID": "s2.html#basic-sf-operations",
    "href": "s2.html#basic-sf-operations",
    "title": "Origin-destination data analysis",
    "section": "",
    "text": "We will start with a simple map of the world. Load the world object from the spData package. Notice the use of :: to say that you want the world object from the spData package.\n\nRPython\n\n\n\nworld = spData::world\n\n\n\n\nworld = gpd.read_file(\n    'https://naturalearth.s3.amazonaws.com/110m_cultural/ne_110m_admin_0_countries.zip'\n)\n\n\n\n\nUse some basic R functions to explore the world object. e.g. class(world), dim(world), head(world), summary(world). Also view the world object by clicking on it in the Environment panel.\nsf objects can be plotted with plot().\n\nRPython\n\n\n\nplot(world)\n\n\n\n\n\n\n\n\n\n\n\nworld = gpd.read_file(\n    'https://naturalearth.s3.amazonaws.com/110m_cultural/ne_110m_admin_0_countries.zip'\n)\nprint(type(world))       # Equivalent to class(world)\nprint(world.shape)       # Equivalent to dim(world)\nprint(world.head())      # Equivalent to head(world)\nprint(world.describe())  # Equivalent to summary(world)\n\n# Plotting the world GeoDataFrame\nworld.plot(figsize=(12, 8))\nplt.title('World Map')\nplt.show()\n\n\n\n\nNote that this makes a map of each column in the data frame. Try some other plotting options\n\nRPython\n\n\n\nworld = spData::world\nplot(world[3:6])\n\n\n\n\n\n\n\nplot(world[\"pop\"])\n\n\n\n\n\n\n\n\n\n\n\n# Since world is a GeoDataFrame, we can select columns by position\n# However, GeoPandas plots the geometry, so we need to specify columns\nworld = gpd.read_file('https://naturalearth.s3.amazonaws.com/110m_cultural/ne_110m_admin_0_countries.zip')\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\nworld.plot(column='POP_EST', ax=axes[0])\nworld.plot(column='GDP_YEAR', ax=axes[1])\nworld.plot(column='CONTINENT', ax=axes[2])\nplt.show()"
  },
  {
    "objectID": "s2.html#basic-spatial-operations",
    "href": "s2.html#basic-spatial-operations",
    "title": "Origin-destination data analysis",
    "section": "",
    "text": "Load the nz and nz_height datasets from the spData package.\n\nRPython\n\n\n\nnz = spData::nz\nnz_height = spData::nz_height\n\n\n\n\nnz = gpd.read_file(\"https://github.com/Nowosad/spData_files/raw/refs/heads/main/data/nz.gpkg\")\nnz_height = gpd.read_file(\"https://github.com/Nowosad/spData_files/raw/refs/heads/main/data/nz_height.gpkg\")\n\n\n\n\nWe can use tidyverse functions like filter and select on sf objects in the same way you did in Practical 1.\n\nRPython\n\n\n\ncanterbury = nz |&gt; filter(Name == \"Canterbury\")\ncanterbury_height = nz_height[canterbury, ]\n\n\n\n\ncanterbury = nz[nz['Name'] == 'Canterbury']\n\n\n\n\nIn this case we filtered the nz object to only include places called Canterbury and then did and intersection to find objects in the nz_height object that are in Canterbury.\nThis syntax is not very clear. But is the equivalent to\n\nRPython\n\n\n\ncanterbury_height = nz_height[canterbury, , op = st_intersects]\n\n\n\n\ncanterbury_height = gpd.overlay(nz_height, canterbury, how='intersection')\n\n\n\n\nThere are many different types of relationships you can use with op. Try ?st_intersects() to see more. For example this would give all the places not in Canterbury\n\nRPython\n\n\n\nnz_height[canterbury, , op = st_disjoint]\n\n\n\n\ncanterbury_height = gpd.sjoin(nz_height, canterbury, op='intersects')\n\n\n\n\n\n\n\nTopological relations between vector geometries, inspired by Figures 1 and 2 in Egenhofer and Herring (1990). The relations for which the function(x, y) is true are printed for each geometry pair, with x represented in pink and y represented in blue. The nature of the spatial relationship for each pair is described by the Dimensionally Extended 9-Intersection Model string."
  },
  {
    "objectID": "next-steps.html",
    "href": "next-steps.html",
    "title": "1 Next Steps for Slides",
    "section": "",
    "text": "Here are suggestions for enhancing the slides for the Data Science for Transport Planning course:\n\n\n\nAdd more detailed session introductions linking to the specific workbooks (s1.qmd, s2.qmd, etc.)\nInclude images from the course slides (e.g., paste-3.png for reproducible research)\nAdd code examples or snippets for setup checks\nInclude a slide on course objectives and learning outcomes\nAdd contact information and GitHub links prominently\n\n\n\n\n\nExpand the recap section with key takeaways from Day 1\nAdd content on spatio-temporal data analysis with examples\nInclude routing and network analysis demonstrations\nAdd best practices section with Git/GitHub workflows\nInclude advanced topics overview with links to s7.qmd\nAdd a feedback slide with QR code for course evaluation\n\n\n\n\n\nAdd consistent branding and color scheme\nInclude more transport-specific examples and datasets\nAdd interactive elements like polls or questions\nInclude references and bibliography sections\nAdd a final thank you slide with contact info and next course info\nEnsure all images are properly sourced and credited\nAdd navigation aids and table of contents\nInclude accessibility features (alt text for images)\n\n\n\n\n\nAdd slides on data sources specific to transport planning (Stats19, OSM, OD data)\nInclude case studies from Leeds or UK transport projects\nAdd slides on ethical considerations in transport data science\nInclude career development and networking opportunities\nAdd slides on publishing and sharing transport research\n\n\n\n\n\nAdd reveal.js plugins for better interactivity\nInclude code highlighting and execution\nAdd transition effects and animations\nEnsure mobile responsiveness\nAdd PDF export options"
  },
  {
    "objectID": "next-steps.html#day-1-slides-enhancements",
    "href": "next-steps.html#day-1-slides-enhancements",
    "title": "1 Next Steps for Slides",
    "section": "",
    "text": "Add more detailed session introductions linking to the specific workbooks (s1.qmd, s2.qmd, etc.)\nInclude images from the course slides (e.g., paste-3.png for reproducible research)\nAdd code examples or snippets for setup checks\nInclude a slide on course objectives and learning outcomes\nAdd contact information and GitHub links prominently"
  },
  {
    "objectID": "next-steps.html#day-2-slides-expansions",
    "href": "next-steps.html#day-2-slides-expansions",
    "title": "1 Next Steps for Slides",
    "section": "",
    "text": "Expand the recap section with key takeaways from Day 1\nAdd content on spatio-temporal data analysis with examples\nInclude routing and network analysis demonstrations\nAdd best practices section with Git/GitHub workflows\nInclude advanced topics overview with links to s7.qmd\nAdd a feedback slide with QR code for course evaluation"
  },
  {
    "objectID": "next-steps.html#general-improvements",
    "href": "next-steps.html#general-improvements",
    "title": "1 Next Steps for Slides",
    "section": "",
    "text": "Add consistent branding and color scheme\nInclude more transport-specific examples and datasets\nAdd interactive elements like polls or questions\nInclude references and bibliography sections\nAdd a final thank you slide with contact info and next course info\nEnsure all images are properly sourced and credited\nAdd navigation aids and table of contents\nInclude accessibility features (alt text for images)"
  },
  {
    "objectID": "next-steps.html#content-additions",
    "href": "next-steps.html#content-additions",
    "title": "1 Next Steps for Slides",
    "section": "",
    "text": "Add slides on data sources specific to transport planning (Stats19, OSM, OD data)\nInclude case studies from Leeds or UK transport projects\nAdd slides on ethical considerations in transport data science\nInclude career development and networking opportunities\nAdd slides on publishing and sharing transport research"
  },
  {
    "objectID": "next-steps.html#technical-enhancements",
    "href": "next-steps.html#technical-enhancements",
    "title": "1 Next Steps for Slides",
    "section": "",
    "text": "Add reveal.js plugins for better interactivity\nInclude code highlighting and execution\nAdd transition effects and animations\nEnsure mobile responsiveness\nAdd PDF export options"
  },
  {
    "objectID": "s1.html",
    "href": "s1.html",
    "title": "Finding, importing and cleaning transport datasets",
    "section": "",
    "text": "In this session, we will explore how to find, download, import, and clean transport-related datasets. Transport data comes from various sources such as government agencies, open data portals, and crowd-sourced platforms. We will learn practical techniques using R to access and prepare this data for analysis.\nThis session covers:\n\nDownloading datasets from OpenStreetMap\nImporting data into R\nBasic data cleaning and exploration\nHands-on exercises"
  },
  {
    "objectID": "s1.html#project-setup",
    "href": "s1.html#project-setup",
    "title": "Finding, importing and cleaning transport datasets",
    "section": "2.1 Project setup",
    "text": "2.1 Project setup\nFollow the guidance in the day 1 slides to set up your project folder or repository if you have not already done so. In summary, you can run something like the following to create a new folder/repository and open it in RStudio or VS Code.\n\ngh CLI toolRShell\n\n\nThe following creates a fresh GitHub repository using the GitHub CLI (recommended).\nNote: you need to have installed the GitHub CLI and authenticated it with your GitHub account.\ncd path/to/your/folder # e.g. cd C:/Users/YourName/Documents\ngh repo create dstp-rl --public --clone # replace 'rl' with your initials\ncode path/to/your/folder/dstp-rl # or open in RStudio\n\n\ndir.create(\"C:/path/to/your/folder/dstp\") # replace with your path\nrstudioapi::openProject(\"C:/path/to/your/folder/dstp\")\n\n\nThe following creates an empty folder using PowerShell or the RStudio/VS Code terminal.\n# After opening a terminal in your chosen IDE/shell\ncd path/to/your/folder # e.g. cd C:/Users/YourName/Documents\nmkdir dstp-rl # replace 'rl' with your initials\n# Then open the folder in your IDE"
  },
  {
    "objectID": "s1.html#openstreetmap-data",
    "href": "s1.html#openstreetmap-data",
    "title": "Finding, importing and cleaning transport datasets",
    "section": "3.1 OpenStreetMap Data",
    "text": "3.1 OpenStreetMap Data\nOpenStreetMap (OSM) provides global geographic data with a focus on human-made entities, including roads. It is therefore very useful for quickly obtaining road network data for transport analysis. A disadvantage of OSM data is that it can be inconsistent in quality and coverage, depending on the area, but for many applications these disadvantages are outweighed by the ease of access and free availability of the data.\nUse the osmextract package to download and extract specific features.\n\nlibrary(osmextract)\n# Download cycleways in West Yorkshire\nwest_yorkshire_cycleways = oe_get(\n  # force_download = TRUE,\n  place = \"West Yorkshire\",\n  extra_tags = c(\"maxspeed\", \"lit\", \"cycleway\"),\n  query = \"SELECT * FROM lines WHERE highway IN ('cycleway', 'path')\"\n)\nplot(st_geometry(west_yorkshire_cycleways))\n\nYou might also be interested in other spatial data in West Yorkshire. For example, you can use the following code to extract amenities in the region:\n\nlibrary(osmextract)\n# Download amenities in West Yorkshire\nwest_yorkshire_amenities = oe_get(\n  layer = \"points\", # We want the point location\n  place = \"West Yorkshire\",\n  extra_tags = c(\"amenity\") \n)\nplot(st_geometry(west_yorkshire_amenities))\n\nwest_yorkshire_amenities$amenity |&gt; table()"
  },
  {
    "objectID": "s1.html#road-traffic-casualty-data-stats19",
    "href": "s1.html#road-traffic-casualty-data-stats19",
    "title": "Finding, importing and cleaning transport datasets",
    "section": "3.2 Road Traffic Casualty Data (STATS19)",
    "text": "3.2 Road Traffic Casualty Data (STATS19)\nThe UK’s road traffic casualty data is available through the stats19 package. This provides data on collisions, casualties, and vehicles.\n\nlibrary(stats19)\n# Download 2020 collision data\ncollisions = get_stats19(year = 2020, type = \"collision\")\n# Download casualty data\ncasualties = get_stats19(year = 2020, type = \"cas\")\n# Download vehicle data\nvehicles = get_stats19(year = 2020, type = \"veh\")"
  },
  {
    "objectID": "s1.html#origin-destination-data",
    "href": "s1.html#origin-destination-data",
    "title": "Finding, importing and cleaning transport datasets",
    "section": "3.3 Origin-Destination Data",
    "text": "3.3 Origin-Destination Data\nThe pct package provides access to the Propensity to Cycle Tool data, which includes origin-destination flows.\n\nlibrary(pct)\n# Download desire lines for Leeds\nleeds_desire_lines = get_pct_lines(region = \"west-yorkshire\")"
  },
  {
    "objectID": "s1.html#boundary-and-census-data",
    "href": "s1.html#boundary-and-census-data",
    "title": "Finding, importing and cleaning transport datasets",
    "section": "3.4 Boundary and Census Data",
    "text": "3.4 Boundary and Census Data\nFor geographic boundaries and census data, you can obtain data directly from the ONS Geoportal or custom dataset tool.\nLoad the data directly from https://geoportal.statistics.gov.uk/ as follows (see Exercises below for more details):\n\nlibrary(sf)\n# Download LSOA boundaries\nurl = \"https://services1.arcgis.com/ESMARspQHYMw9BZ9/arcgis/rest/services/Lower_layer_Super_Output_Areas_December_2021_Boundaries_EW_BFE_V10/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson\"\nlsoa_boundaries = st_read(url)\n\nAll results from the census can be obtained from nomis. It is possible to obtain the data programmatically in R using nomisr; check its documentation if you are interested."
  },
  {
    "objectID": "s1.html#basic-cleaning-example",
    "href": "s1.html#basic-cleaning-example",
    "title": "Finding, importing and cleaning transport datasets",
    "section": "4.1 Basic Cleaning Example",
    "text": "4.1 Basic Cleaning Example\n\n# Clean collision data\ncollisions_clean = collisions |&gt;\n  # Remove rows with missing coordinates\n  drop_na(location_easting_osgr,location_northing_osgr) |&gt;\n  # Convert to sf object (spatial)\n  st_as_sf(coords = c(\"location_easting_osgr\", \"location_northing_osgr\"), crs = 27700) |&gt;\n  # Select relevant columns\n  select(accident_index, date, speed_limit, accident_severity)"
  },
  {
    "objectID": "s1.html#handling-missing-data",
    "href": "s1.html#handling-missing-data",
    "title": "Finding, importing and cleaning transport datasets",
    "section": "4.2 Handling Missing Data",
    "text": "4.2 Handling Missing Data\nThere is no single strategy for dealing with missing data. The approach you adopt depends on the context. A simple strategy to impute missing data is to use a constant value. The following example uses the median value to fill missing speed limits, which might be a valid approach if your dataset contains very similar road types.\n\n# Check for missing values\nsummary(collisions_clean)\n# Impute or remove missing values\ncollisions_clean = collisions_clean |&gt;\n  mutate(speed_limit = ifelse(is.na(speed_limit), median(speed_limit, na.rm = TRUE), speed_limit))"
  },
  {
    "objectID": "s1.html#download-and-explore-stats19-data",
    "href": "s1.html#download-and-explore-stats19-data",
    "title": "Finding, importing and cleaning transport datasets",
    "section": "5.1 Download and Explore STATS19 Data",
    "text": "5.1 Download and Explore STATS19 Data\n\nDownload road traffic collision data for 2019 using the stats19 package.\nExplore the structure of the data using str() and summary().\nCreate a simple plot showing the number of collisions by severity.\n\n\n# Your code here"
  },
  {
    "objectID": "s1.html#extract-osm-features",
    "href": "s1.html#extract-osm-features",
    "title": "Finding, importing and cleaning transport datasets",
    "section": "5.2 Extract OSM Features",
    "text": "5.2 Extract OSM Features\n\nUse osmextract to download all supermarkets in your chosen city.\nConvert the data to an sf object and plot it on a map.\nCount the number of supermarkets by type.\n\n\n# Your code here"
  },
  {
    "objectID": "s1.html#clean-and-visualise-od-data",
    "href": "s1.html#clean-and-visualise-od-data",
    "title": "Finding, importing and cleaning transport datasets",
    "section": "5.3 Clean and Visualise OD Data",
    "text": "5.3 Clean and Visualise OD Data\n\nDownload origin-destination data for a region using the pct package.\nClean the data by removing any invalid geometries.\nCreate a map showing the desire lines coloured by cycling potential.\n\n\n# Your code here"
  },
  {
    "objectID": "s1.html#importing-official-boundary-data",
    "href": "s1.html#importing-official-boundary-data",
    "title": "Finding, importing and cleaning transport datasets",
    "section": "5.4 Importing official boundary data",
    "text": "5.4 Importing official boundary data\n\n\nNavigate to the ONS Geoportal and search for Local Enterprise Partnerships (LEPs), using the checkboxes to find only ‘Feature Services’.\nGet the URL of the endpoint for GeoJSON format of the 2021 LEP boundaries. Note: you need to click on the bottom right “I want to use this service” button and then on the “View API Resources” link to find the URL.\nImport the downloaded GeoJSON file into R using the sf package.\nPlot the result. It should look something like this:\n\n\nplot(sf::st_geometry(leps))"
  },
  {
    "objectID": "s1.html#bonus-data-quality-assessment",
    "href": "s1.html#bonus-data-quality-assessment",
    "title": "Finding, importing and cleaning transport datasets",
    "section": "5.5 Bonus: Data Quality Assessment",
    "text": "5.5 Bonus: Data Quality Assessment\n\nChoose a dataset you have downloaded.\nAssess its quality by checking for:\n\nMissing values\nOutliers\nInconsistent data types\n\nDocument any issues found and how you would address them.\n\n\n# Your code here"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Day 1 Slides\n\n\n\n\n\n\n\n\nTime\nSession\n\n\n\n\n\n10:00 - 11:00\nIntroduction to Data Science for Transport Planning\n\n\n\n11:00 - 12:30\nFinding, importing and cleaning transport datasets- Origin-destination datasets- OpenStreetMap (OSM) and Ordnance Survey (OS) OpenRoads datasets- Stats19 road safety data\n\n\n\n12:30 - 13:30\nLunch\n\n\n\n13:30 - 15:00\nOrigin-destination data analysis\n\n\n\n15:00 - 15:15\nBreak and refreshments\n\n\n\n15:15 - 17:00\nOD Transport data visualisation",
    "crumbs": [
      "Schedule"
    ]
  },
  {
    "objectID": "schedule.html#day-1-introduction-to-rrstudio",
    "href": "schedule.html#day-1-introduction-to-rrstudio",
    "title": "Schedule",
    "section": "",
    "text": "Day 1 Slides\n\n\n\n\n\n\n\n\nTime\nSession\n\n\n\n\n\n10:00 - 11:00\nIntroduction to Data Science for Transport Planning\n\n\n\n11:00 - 12:30\nFinding, importing and cleaning transport datasets- Origin-destination datasets- OpenStreetMap (OSM) and Ordnance Survey (OS) OpenRoads datasets- Stats19 road safety data\n\n\n\n12:30 - 13:30\nLunch\n\n\n\n13:30 - 15:00\nOrigin-destination data analysis\n\n\n\n15:00 - 15:15\nBreak and refreshments\n\n\n\n15:15 - 17:00\nOD Transport data visualisation",
    "crumbs": [
      "Schedule"
    ]
  },
  {
    "objectID": "schedule.html#day-2",
    "href": "schedule.html#day-2",
    "title": "Schedule",
    "section": "2 Day 2",
    "text": "2 Day 2\nDay 2 Slides\n\n\n\n\n\n\n\n\nTime\nSession\n\n\n\n\n\n09:00 - 10:45\nSpatio-temporal data- Demonstration of open-access OD data with hourly resolution- Demonstration with stats19 data for road safety analysis\n\n\n\n10:45 - 11:15\nBreak and refreshments\n\n\n\n11:15 - 12:30\nRouting and route network analysis- Setting up an interface to a routing engine and using it to calculate routes and distances using GTFS data\n\n\n\n12:30 - 13:30\nLunch\n\n\n\n13:30 - 15:00\nBest practices for data science in transport planning- Version control with Git and GitHub- Reproducible research with Quarto\n\n\n\n15:00 - 16:00\nAdvanced topics- Visualising large datasets- Route network integration (e.g., OSM networks)- Deploying your work as web applications",
    "crumbs": [
      "Schedule"
    ]
  },
  {
    "objectID": "routing-engine.html",
    "href": "routing-engine.html",
    "title": "Deploying a Dockerized Routing Engine on GCP",
    "section": "",
    "text": "This guide provides a minimal and robust method for deploying a Dockerized OpenTripPlanner (OTP) server on Google Cloud Platform (GCP), adhering to modern best practices.\nCore Principles:\n\nDeclarative Deployment: Use create-with-container for reliable, atomic deployments.\nLeast Privilege Security: Employ a dedicated Service Account with minimal permissions.\nOptimized Images: Use multi-stage Docker builds for smaller, more secure images.\nCost Efficiency: Utilize Spot VMs for non-critical workloads.\n\n\n\n\nPrepare your local environment and GCP project. This only needs to be done once.\n\nInstall Local Tools & Configure GCP:\n\nInstall the Google Cloud SDK and Docker.\nLog in to GCP and initialize your project:\n\n\ngcloud init\n- Enable required APIs:\ngcloud services enable compute.googleapis.com artifactregistry.googleapis.com iam.googleapis.com\n- Configure Docker to authenticate with Artifact Registry (replace `europe-west2` with your region):\ngcloud auth configure-docker europe-west2-docker.pkg.dev\n\nCreate the Dockerfile:\nSave the following as routing-engine/Dockerfile. This version includes Nginx and Certbot to automatically handle HTTPS.\n\n# ---- Build Stage ----\nFROM ubuntu:22.04 as builder\nRUN apt-get update && apt-get install -y wget unzip && rm -rf /var/lib/apt/lists/*\nWORKDIR /source\nRUN wget https://github.com/ITSLeeds/TDS/releases/download/0.20.1/otp_TDS.zip && unzip otp_TDS.zip\n\n# ---- Final Stage ----\nFROM eclipse-temurin:8-jre-focal\nRUN apt-get update && apt-get install -y nginx certbot python3-certbot-nginx supervisor && rm -rf /var/lib/apt/lists/*\nWORKDIR /app\nCOPY --from=builder /source/otp_TDS/ .\nRUN mkdir -p graphs\nRUN rm -f /etc/nginx/sites-enabled/default\nCOPY nginx.conf /etc/nginx/sites-available/otp\nRUN ln -s /etc/nginx/sites-available/otp /etc/nginx/sites-enabled/\nCOPY supervisord.conf /etc/supervisor/conf.d/supervisord.conf\nCOPY startup.sh /startup.sh\nRUN chmod +x /startup.sh\nEXPOSE 80 443 8080\nCMD [\"/startup.sh\"]\n*Note: You will also need to create `nginx.conf`, `supervisord.conf`, and `startup.sh` in your project directory.*\n\nCreate GCP Resources:\n\nArtifact Registry Repository:\n\n\ngcloud artifacts repositories create routing-engine \\\n  --repository-format=docker \\\n  --location=europe-west2 \\\n  --project=shiny-server-154518\n- **Service Account:**\ngcloud iam service-accounts create otp-vm-sa --display-name=\"OTP VM Service Account\" --project=shiny-server-154518\ngcloud projects add-iam-policy-binding shiny-server-154518 \\\n  --member=\"serviceAccount:otp-vm-sa@shiny-server-154518.iam.gserviceaccount.com\" \\\n  --role=\"roles/artifactregistry.reader\"\n\n\n\n\nNow, build the Docker image and deploy it to a new VM.\n\nBuild and Push the Docker Image:\n\nexport IMAGE_URI=\"europe-west2-docker.pkg.dev/shiny-server-154518/routing-engine/routing-engine:latest\"\ndocker build -t $IMAGE_URI ./routing-engine/\ndocker push $IMAGE_URI\n\nDeploy the VM and Create Firewall Rule:\n\n# Create the VM with the container\ngcloud compute instances create-with-container routing-vm \\\n  --zone=europe-west2-a \\\n  --machine-type=e2-medium \\\n  --provisioning-model=SPOT \\\n  --service-account=otp-vm-sa@shiny-server-154518.iam.gserviceaccount.com \\\n  --tags=allow-http-traffic \\\n  --container-image=$IMAGE_URI \\\n  --container-restart-policy=always\n\n# Create a firewall rule to allow traffic\ngcloud compute firewall-rules create allow-otp-traffic \\\n  --allow tcp:80,tcp:443,tcp:8080 \\\n  --source-ranges=0.0.0.0/0 \\\n  --target-tags=allow-http-traffic\n\n\n\n\nAfter deployment, verify that the server is running correctly.\n\nGet the External IP Address:\n\nexport EXTERNAL_IP=$(gcloud compute instances describe routing-vm --zone=europe-west2-a --format='get(networkInterfaces[0].accessConfigs[0].natIP)')\necho \"Server IP: $EXTERNAL_IP\"\n\nTest the API:\n\nVia HTTPS (recommended):\n\n\ncurl \"https://otp.robinlovelace.net/otp/routers/west-yorkshire/plan?fromPlace=53.8003,-1.5491&toPlace=53.8008,-1.5497&mode=CAR\"\n- **Via direct IP and port (for teaching/debugging):**\ncurl \"http://$EXTERNAL_IP:8080/otp/routers/west-yorkshire/plan?fromPlace=53.8003,-1.5491&toPlace=53.8008,-1.5497&mode=CAR\"\n- **Interactive Map:** Open `https://otp.robinlovelace.net` in your browser.\n\nView Logs:\n\ngcloud logging read \"resource.type=gce_instance AND resource.labels.instance_id=$(gcloud compute instances describe routing-vm --zone=europe-west2-a --format='get(id)')\" --limit 100\n\n\n\n\nUpdating the Server:\nTo apply changes (e.g., an updated Dockerfile), you must rebuild the image and redeploy the VM.\n\nDelete the existing VM:\n\ngcloud compute instances delete routing-vm --zone=europe-west2-a --quiet\n\nFollow Step 2 again to build the new image and deploy the VM.\n\nCleaning Up Resources:\nTo avoid ongoing charges, delete the resources when you are finished.\n# Delete the VM instance\ngcloud compute instances delete routing-vm --zone=europe-west2-a --quiet\n\n# Delete the firewall rule\ngcloud compute firewall-rules delete allow-otp-traffic --quiet\n\n# Delete the service account\ngcloud iam service-accounts delete otp-vm-sa@shiny-server-154518.iam.gserviceaccount.com --quiet\n\n# Optional: Delete the Docker image from Artifact Registry\ngcloud artifacts repositories delete routing-engine --location=europe-west2 --quiet"
  },
  {
    "objectID": "routing-engine.html#introduction",
    "href": "routing-engine.html#introduction",
    "title": "Deploying a Dockerized Routing Engine on GCP",
    "section": "",
    "text": "This guide provides a minimal and robust method for deploying a Dockerized OpenTripPlanner (OTP) server on Google Cloud Platform (GCP), adhering to modern best practices.\nCore Principles:\n\nDeclarative Deployment: Use create-with-container for reliable, atomic deployments.\nLeast Privilege Security: Employ a dedicated Service Account with minimal permissions.\nOptimized Images: Use multi-stage Docker builds for smaller, more secure images.\nCost Efficiency: Utilize Spot VMs for non-critical workloads.\n\n\n\n\nPrepare your local environment and GCP project. This only needs to be done once.\n\nInstall Local Tools & Configure GCP:\n\nInstall the Google Cloud SDK and Docker.\nLog in to GCP and initialize your project:\n\n\ngcloud init\n- Enable required APIs:\ngcloud services enable compute.googleapis.com artifactregistry.googleapis.com iam.googleapis.com\n- Configure Docker to authenticate with Artifact Registry (replace `europe-west2` with your region):\ngcloud auth configure-docker europe-west2-docker.pkg.dev\n\nCreate the Dockerfile:\nSave the following as routing-engine/Dockerfile. This version includes Nginx and Certbot to automatically handle HTTPS.\n\n# ---- Build Stage ----\nFROM ubuntu:22.04 as builder\nRUN apt-get update && apt-get install -y wget unzip && rm -rf /var/lib/apt/lists/*\nWORKDIR /source\nRUN wget https://github.com/ITSLeeds/TDS/releases/download/0.20.1/otp_TDS.zip && unzip otp_TDS.zip\n\n# ---- Final Stage ----\nFROM eclipse-temurin:8-jre-focal\nRUN apt-get update && apt-get install -y nginx certbot python3-certbot-nginx supervisor && rm -rf /var/lib/apt/lists/*\nWORKDIR /app\nCOPY --from=builder /source/otp_TDS/ .\nRUN mkdir -p graphs\nRUN rm -f /etc/nginx/sites-enabled/default\nCOPY nginx.conf /etc/nginx/sites-available/otp\nRUN ln -s /etc/nginx/sites-available/otp /etc/nginx/sites-enabled/\nCOPY supervisord.conf /etc/supervisor/conf.d/supervisord.conf\nCOPY startup.sh /startup.sh\nRUN chmod +x /startup.sh\nEXPOSE 80 443 8080\nCMD [\"/startup.sh\"]\n*Note: You will also need to create `nginx.conf`, `supervisord.conf`, and `startup.sh` in your project directory.*\n\nCreate GCP Resources:\n\nArtifact Registry Repository:\n\n\ngcloud artifacts repositories create routing-engine \\\n  --repository-format=docker \\\n  --location=europe-west2 \\\n  --project=shiny-server-154518\n- **Service Account:**\ngcloud iam service-accounts create otp-vm-sa --display-name=\"OTP VM Service Account\" --project=shiny-server-154518\ngcloud projects add-iam-policy-binding shiny-server-154518 \\\n  --member=\"serviceAccount:otp-vm-sa@shiny-server-154518.iam.gserviceaccount.com\" \\\n  --role=\"roles/artifactregistry.reader\"\n\n\n\n\nNow, build the Docker image and deploy it to a new VM.\n\nBuild and Push the Docker Image:\n\nexport IMAGE_URI=\"europe-west2-docker.pkg.dev/shiny-server-154518/routing-engine/routing-engine:latest\"\ndocker build -t $IMAGE_URI ./routing-engine/\ndocker push $IMAGE_URI\n\nDeploy the VM and Create Firewall Rule:\n\n# Create the VM with the container\ngcloud compute instances create-with-container routing-vm \\\n  --zone=europe-west2-a \\\n  --machine-type=e2-medium \\\n  --provisioning-model=SPOT \\\n  --service-account=otp-vm-sa@shiny-server-154518.iam.gserviceaccount.com \\\n  --tags=allow-http-traffic \\\n  --container-image=$IMAGE_URI \\\n  --container-restart-policy=always\n\n# Create a firewall rule to allow traffic\ngcloud compute firewall-rules create allow-otp-traffic \\\n  --allow tcp:80,tcp:443,tcp:8080 \\\n  --source-ranges=0.0.0.0/0 \\\n  --target-tags=allow-http-traffic\n\n\n\n\nAfter deployment, verify that the server is running correctly.\n\nGet the External IP Address:\n\nexport EXTERNAL_IP=$(gcloud compute instances describe routing-vm --zone=europe-west2-a --format='get(networkInterfaces[0].accessConfigs[0].natIP)')\necho \"Server IP: $EXTERNAL_IP\"\n\nTest the API:\n\nVia HTTPS (recommended):\n\n\ncurl \"https://otp.robinlovelace.net/otp/routers/west-yorkshire/plan?fromPlace=53.8003,-1.5491&toPlace=53.8008,-1.5497&mode=CAR\"\n- **Via direct IP and port (for teaching/debugging):**\ncurl \"http://$EXTERNAL_IP:8080/otp/routers/west-yorkshire/plan?fromPlace=53.8003,-1.5491&toPlace=53.8008,-1.5497&mode=CAR\"\n- **Interactive Map:** Open `https://otp.robinlovelace.net` in your browser.\n\nView Logs:\n\ngcloud logging read \"resource.type=gce_instance AND resource.labels.instance_id=$(gcloud compute instances describe routing-vm --zone=europe-west2-a --format='get(id)')\" --limit 100\n\n\n\n\nUpdating the Server:\nTo apply changes (e.g., an updated Dockerfile), you must rebuild the image and redeploy the VM.\n\nDelete the existing VM:\n\ngcloud compute instances delete routing-vm --zone=europe-west2-a --quiet\n\nFollow Step 2 again to build the new image and deploy the VM.\n\nCleaning Up Resources:\nTo avoid ongoing charges, delete the resources when you are finished.\n# Delete the VM instance\ngcloud compute instances delete routing-vm --zone=europe-west2-a --quiet\n\n# Delete the firewall rule\ngcloud compute firewall-rules delete allow-otp-traffic --quiet\n\n# Delete the service account\ngcloud iam service-accounts delete otp-vm-sa@shiny-server-154518.iam.gserviceaccount.com --quiet\n\n# Optional: Delete the Docker image from Artifact Registry\ngcloud artifacts repositories delete routing-engine --location=europe-west2 --quiet"
  },
  {
    "objectID": "s6.html",
    "href": "s6.html",
    "title": "Best practices for data science in transport planning",
    "section": "",
    "text": "Placeholder for session 6 content.\n\n\n\nReuseCC BY-SA 4.0Copyright© 2025 Robin Lovelace"
  },
  {
    "objectID": "s5.html",
    "href": "s5.html",
    "title": "Routing and route network analysis",
    "section": "",
    "text": "This session demonstrates routing and network analysis techniques. By the end of this session, you should be able to:\n\nUnderstand the principles of routing and network analysis\nUse routing services such as OpenTripPlanner for multi-modal routing\nCreate and analyze route networks\nApply network centrality measures\n\n\n\n\nif (!require(\"pak\")) install.packages(\"pak\")\npak::pkg_install(c(\"sf\", \"tidyverse\", \"stplanr\", \"dodgr\", \"opentripplanner\", \"tmap\", \"osmextract\", \"lwgeom\"))\n\n\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(stplanr)\nlibrary(dodgr)\nlibrary(opentripplanner)\nlibrary(tmap)\nlibrary(osmextract)\nlibrary(lwgeom)\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "s5.html#prerequisites",
    "href": "s5.html#prerequisites",
    "title": "Routing and route network analysis",
    "section": "",
    "text": "if (!require(\"pak\")) install.packages(\"pak\")\npak::pkg_install(c(\"sf\", \"tidyverse\", \"stplanr\", \"dodgr\", \"opentripplanner\", \"tmap\", \"osmextract\", \"lwgeom\"))\n\n\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(stplanr)\nlibrary(dodgr)\nlibrary(opentripplanner)\nlibrary(tmap)\nlibrary(osmextract)\nlibrary(lwgeom)\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "s5.html#connecting-to-otp",
    "href": "s5.html#connecting-to-otp",
    "title": "Routing and route network analysis",
    "section": "2.1 Connecting to OTP",
    "text": "2.1 Connecting to OTP\n\notpcon = otp_connect(\n  hostname = \"otp.robinlovelace.net\",\n  ssl = TRUE,\n  port = 443,\n  router = \"west-yorkshire\"\n)"
  },
  {
    "objectID": "s5.html#basic-routing",
    "href": "s5.html#basic-routing",
    "title": "Routing and route network analysis",
    "section": "2.2 Basic Routing",
    "text": "2.2 Basic Routing\n\n# Create a simple walking route\nroute_walk = otp_plan(\n  otpcon = otpcon,\n  fromPlace = c(-1.55555, 53.81005), # Longitude, Latitude\n  toPlace = c(-1.54710, 53.79519),\n  mode = \"WALK\"\n)"
  },
  {
    "objectID": "s5.html#multi-modal-routing",
    "href": "s5.html#multi-modal-routing",
    "title": "Routing and route network analysis",
    "section": "2.3 Multi-Modal Routing",
    "text": "2.3 Multi-Modal Routing\n\n# Public transport route\nroute_transit = otp_plan(\n  otpcon = otpcon,\n  fromPlace = c(-1.55555, 53.81005),\n  toPlace = c(-1.54710, 53.79519),\n  mode = c(\"WALK\", \"TRANSIT\")\n)\n\n# Cycling with public transport\nroute_bike_transit = otp_plan(\n  otpcon = otpcon,\n  fromPlace = c(-1.55555, 53.81005),\n  toPlace = c(-1.54710, 53.79519),\n  mode = c(\"BICYCLE\", \"TRANSIT\")\n)"
  },
  {
    "objectID": "s5.html#loading-od-data",
    "href": "s5.html#loading-od-data",
    "title": "Routing and route network analysis",
    "section": "3.1 Loading OD Data",
    "text": "3.1 Loading OD Data\nWe’ll import and apply basic preprocessing steps to desire lines from the National Trip End Model (NTEM). Note that we keep the raw data unchanged for reproducibility.\n\n# Load desire lines data\ndesire_lines_raw = read_sf(\"https://github.com/ITSLeeds/TDS/releases/download/22/NTEM_flow.geojson\")\ndesire_lines = desire_lines_raw |&gt;\n  select(from, to, all, walk, drive, cycle)\n\n# Load zone centroids\ncentroids = read_sf(\"https://github.com/ITSLeeds/TDS/releases/download/22/NTEM_cents.geojson\")\n\nWe’ll also create a smaller subset of the desire lines for demonstration purposes.\n\n# Filter for top 5 desire lines by total trips\ndesire_top = desire_lines |&gt;\n  slice_max(order_by = all, n = 5)"
  },
  {
    "objectID": "s5.html#visualizing-desire-lines",
    "href": "s5.html#visualizing-desire-lines",
    "title": "Routing and route network analysis",
    "section": "3.2 Visualizing Desire Lines",
    "text": "3.2 Visualizing Desire Lines\n\ntm_shape(desire_lines) +\n  tm_lines(\n    col = \"all\",\n    lwd = \"all\",\n    lwd.scale = tm_scale_continuous(values.scale = 10),\n    col.scale = tm_scale_continuous(values = \"-viridis\")\n  ) +\n  tm_shape(centroids) +\n  tm_dots(fill = \"red\", size = 0.5)\n\nExtract start and end points as follows:\n\n# Extract start and end points\nfromPlace = sf::st_sf(\n  data.frame(id = desire_top$from),\n  geometry = lwgeom::st_startpoint(desire_top)\n)\ntoPlace = sf::st_sf(\n  data.frame(id = desire_top$to),\n  geometry = lwgeom::st_endpoint(desire_top)\n)"
  },
  {
    "objectID": "s5.html#calculating-routes",
    "href": "s5.html#calculating-routes",
    "title": "Routing and route network analysis",
    "section": "3.3 Calculating Routes",
    "text": "3.3 Calculating Routes\n\n# Calculate driving routes for top desire lines\nroutes_drive_top = otp_plan(\n  otpcon = otpcon,\n  fromPlace = fromPlace,\n  toPlace = toPlace,\n  fromID = fromPlace$id,\n  toID = toPlace$id,\n  mode = \"CAR\"\n)"
  },
  {
    "objectID": "s5.html#visualizing-routes",
    "href": "s5.html#visualizing-routes",
    "title": "Routing and route network analysis",
    "section": "3.4 Visualizing Routes",
    "text": "3.4 Visualizing Routes\n\ntm_shape(routes_drive_top) +\n  tm_lines(col = \"blue\", lwd = 3)"
  },
  {
    "objectID": "s5.html#joining-routes-to-create-a-route-network",
    "href": "s5.html#joining-routes-to-create-a-route-network",
    "title": "Routing and route network analysis",
    "section": "4.1 Joining routes to create a route network",
    "text": "4.1 Joining routes to create a route network\nThe full dataset can be loaded as follows:\n\n# Load more comprehensive route data\nroutes_drive = read_sf(\"https://github.com/ITSLeeds/TDS/releases/download/22/routes_drive.geojson\")\nroutes_transit = read_sf(\"https://github.com/ITSLeeds/TDS/releases/download/22/routes_transit.geojson\")\n\nWe’ll join this with the desire lines data to get trip counts associated with each route.\n\nnames(desire_lines)\nnrow(desire_lines)\nnames(routes_drive)\nnrow(routes_drive)\nnrow(routes_transit)\n\n\nroutes_drive_joined = dplyr::left_join(\n  routes_drive |&gt;\n    rename(from = fromPlace, to = toPlace),\n  desire_lines |&gt;\n    sf::st_drop_geometry()\n)\n\n\nroutes_transit_joined = dplyr::left_join(\n  routes_transit |&gt;\n    rename(from = fromPlace, to = toPlace),\n  desire_lines |&gt;\n    sf::st_drop_geometry()\n)"
  },
  {
    "objectID": "s5.html#aggregating-routes",
    "href": "s5.html#aggregating-routes",
    "title": "Routing and route network analysis",
    "section": "4.2 Aggregating Routes",
    "text": "4.2 Aggregating Routes\n\n# Create route network by aggregating overlapping routes\nrnet_drive = overline(routes_drive_joined, \"drive\")"
  },
  {
    "objectID": "s5.html#visualizing-route-networks",
    "href": "s5.html#visualizing-route-networks",
    "title": "Routing and route network analysis",
    "section": "4.3 Visualizing Route Networks",
    "text": "4.3 Visualizing Route Networks\n\ntm_shape(rnet_drive) +\n  tm_lines(\n    col = \"drive\",\n    col.scale = tm_scale_intervals(values = \"-viridis\", style = \"jenks\"),\n    lwd = 2\n  )"
  },
  {
    "objectID": "s5.html#preparing-network-data",
    "href": "s5.html#preparing-network-data",
    "title": "Routing and route network analysis",
    "section": "5.1 Preparing Network Data",
    "text": "5.1 Preparing Network Data\n\nzones = zonebuilder::zb_zone(\"Leeds\", n_circles = 3)\nstudy_area = zones |&gt;\n  sf::st_union()\nextra_tags = c(\n  \"maxspeed\",\n  \"lit\",\n  \"cycleway\"\n)\nroads = osmextract::oe_get_network(\n  mode= \"driving\",\n  place = study_area,\n  boundary = study_area,\n  boundary_type = \"clipsrc\",\n  extra_tags = extra_tags\n)\n\n# Filter for main roads\nroads = roads |&gt;\n  filter(!is.na(highway)) |&gt;\n  filter(highway %in% c(\"primary\", \"secondary\", \"tertiary\", \"residential\", \"unclassified\")) |&gt;\n  sf::st_cast(\"LINESTRING\") \n\n# Create network graph\ngraph = weight_streetnet(roads)"
  },
  {
    "objectID": "s5.html#calculating-centrality",
    "href": "s5.html#calculating-centrality",
    "title": "Routing and route network analysis",
    "section": "5.2 Calculating Centrality",
    "text": "5.2 Calculating Centrality\n\n# Calculate betweenness centrality\ncentrality = dodgr_centrality(graph)\n\n# Convert back to spatial format\ncentrality_sf = dodgr_to_sf(centrality)"
  },
  {
    "objectID": "s5.html#visualizing-centrality",
    "href": "s5.html#visualizing-centrality",
    "title": "Routing and route network analysis",
    "section": "5.3 Visualizing Centrality",
    "text": "5.3 Visualizing Centrality\n\ntm_shape(centrality_sf) +\n  tm_lines(\n    col = \"centrality\",\n    col.scale = tm_scale_intervals(values = \"-viridis\", style = \"fisher\"),\n    lwd = 3\n  )"
  },
  {
    "objectID": "s5.html#exercise-1-basic-routing",
    "href": "s5.html#exercise-1-basic-routing",
    "title": "Routing and route network analysis",
    "section": "6.1 Exercise 1: Basic Routing",
    "text": "6.1 Exercise 1: Basic Routing\n\nConnect to the OpenTripPlanner server\nCalculate a walking route between two points in Leeds\nVisualize the route on a map\n\n\n# Your code here"
  },
  {
    "objectID": "s5.html#exercise-2-multi-modal-routing",
    "href": "s5.html#exercise-2-multi-modal-routing",
    "title": "Routing and route network analysis",
    "section": "6.2 Exercise 2: Multi-Modal Routing",
    "text": "6.2 Exercise 2: Multi-Modal Routing\n\nCalculate routes using different modes (walk, transit, bicycle+transit)\nCompare the travel times and distances\nVisualize the different route options\n\n\n# Your code here"
  },
  {
    "objectID": "s5.html#exercise-3-desire-lines-analysis",
    "href": "s5.html#exercise-3-desire-lines-analysis",
    "title": "Routing and route network analysis",
    "section": "6.3 Exercise 3: Desire Lines Analysis",
    "text": "6.3 Exercise 3: Desire Lines Analysis\n\nLoad the desire lines dataset\nFilter for the top 5 desire lines by total trips\nCreate a map showing the desire lines colored by mode share\n\n\n# Your code here"
  },
  {
    "objectID": "s5.html#exercise-4-route-network-creation",
    "href": "s5.html#exercise-4-route-network-creation",
    "title": "Routing and route network analysis",
    "section": "6.4 Exercise 4: Route Network Creation",
    "text": "6.4 Exercise 4: Route Network Creation\n\nLoad route data for a specific mode\nCreate a route network using overline()\nCompare the route network visualization with individual routes\n\n\n# Your code here"
  },
  {
    "objectID": "s5.html#exercise-5-network-centrality",
    "href": "s5.html#exercise-5-network-centrality",
    "title": "Routing and route network analysis",
    "section": "6.5 Exercise 5: Network Centrality",
    "text": "6.5 Exercise 5: Network Centrality\n\nDownload road network data for a small area\nCalculate betweenness centrality\nIdentify the most critical roads in the network\n\n\n# Your code here"
  },
  {
    "objectID": "collisions.html",
    "href": "collisions.html",
    "title": "Road traffic collisions",
    "section": "",
    "text": "1 Road traffic collisions\nPlaceholder for road traffic collisions example.\nThis page will contain an analysis using stats19 data for Leeds.\n\n\n\n\nReuseCC BY-SA 4.0Copyright© 2025 Robin Lovelace",
    "crumbs": [
      "Examples",
      "Road traffic collisions"
    ]
  },
  {
    "objectID": "s3.html",
    "href": "s3.html",
    "title": "OD Transport data visualisation",
    "section": "",
    "text": "Building upon the previous session on “Origin-destination data analysis”, we will advance this topic by examining data visualisation techniques for OD transport data.\nBy the end of this session, you should be able to:\n\nLoad and preprocess origin-destination flow data\nCreate visualizations using OD desire lines and proportional symbol maps\nCompare transport flows across different modes (walking, driving, and cycling)\nAnalyse and visualise temporal changes in OD flows, using data from the London Cycle Hire System as an example\n\nBefore getting your hands on the coding, let’s introduce some important ideas with a short lecture. (see slides)"
  },
  {
    "objectID": "s3.html#summary",
    "href": "s3.html#summary",
    "title": "OD Transport data visualisation",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nIn this session, we explored how to effectively visualise origin-destination transport data to understand travel patterns and flows. We learned to create flow maps using desire lines and proportional symbols, and compare travel patterns across different transport modes.\nThrough hands-on analysis of the London Cycle Hire System during a Tube strike, we learned how transport disruptions create measurable changes in travel behavior and flows. The spatial analysis techniques covered — including buffer analysis and geometric operations—provide essential tools for understanding the relationship between transport infrastructure and user behaviuor. We practiced skills in data manipulation, joining datasets across different dates, and creating change of flow maps that effectively communicate complex spatial patterns.\nThese OD transport data visualisation and analysis capabilities are fundamental for evidence-based transport planning, and related skills can support decision-making for infrastructure development and policy interventions in real-world transport systems."
  },
  {
    "objectID": "slides/day1.html#welcome",
    "href": "slides/day1.html#welcome",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Welcome!",
    "text": "Welcome!\nData Science for Transport Planning\n2-day course\n18-19 September 2025"
  },
  {
    "objectID": "slides/day1.html#agenda",
    "href": "slides/day1.html#agenda",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Agenda",
    "text": "Agenda\n\n10:00-11:00 Introduction to Data Science for Transport Planning\n11:00-12:30 Finding, importing and cleaning transport datasets\n12:30-13:30 Lunch\n13:30-15:00 Origin-destination data analysis\n15:00-15:15 Break and refreshments\n15:15-17:00 OD Transport data visualisation"
  },
  {
    "objectID": "slides/day1.html#prerequisites",
    "href": "slides/day1.html#prerequisites",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Prerequisites",
    "text": "Prerequisites\nTo run the code\n\nComputer to run the code\n\nEither: A laptop with R, RStudio or VS Code and Docker or similar installed to run the code locally\nOr: Access to a cloud-based environment for data science (e.g., GitHub Codespaces or Posit Cloud)"
  },
  {
    "objectID": "slides/day1.html#learn-and-share",
    "href": "slides/day1.html#learn-and-share",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Learn and share",
    "text": "Learn and share\nThe following will help:\n\nAn interest in transport planning and knowledge of transport datasets\nA willingness to learn and share\nA GitHub account (to ask questions on the Discussions page and share your own code)\nFamiliarity with data science tools, e.g. R, Python, RStudio, VS Code"
  },
  {
    "objectID": "slides/day1.html#housekeeping",
    "href": "slides/day1.html#housekeeping",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Housekeeping",
    "text": "Housekeeping\n\nConnect to the UoL-Guest Wi-Fi network and enter your details.\nGitHub account sign-up if not done already.\nCoffee and lunch: in the social space just outside this room\nToilets\n\nGents toilets can be found on first and ground floors.\nLadies toilets on the middle and far staircases and ground floor.\nAccessible toilet facilities including a gender neutral toilet, are available on the lower ground floor."
  },
  {
    "objectID": "slides/day1.html#housekeeping-ii",
    "href": "slides/day1.html#housekeeping-ii",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Housekeeping II",
    "text": "Housekeeping II\n\nFire Alarm\n\nIf the alarm sounds, leave the building via the ground floor.\nThe assembly point is the grassed area outside\n\nUse of Extension Leads & Adapters\n\nCube adapters are prohibited.\nInternational chargers are advised against.\nAlternative plugs can be logged/loaned out from the Facilities Office."
  },
  {
    "objectID": "slides/day1.html#wifi",
    "href": "slides/day1.html#wifi",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "WiFi",
    "text": "WiFi"
  },
  {
    "objectID": "slides/day1.html#setup-check",
    "href": "slides/day1.html#setup-check",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Setup check",
    "text": "Setup check\nTo check you have the necessary software installed, try running the following code.\n\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!require(\"pak\")) install.packages(\"pak\")\nif (!require(\"pak\")) install.packages(\"pak\")\npkgs = c(\n    \"sf\",\n    \"tidyverse\",\n    \"tmap\",\n    \"stats19\",\n    \"stplanr\",\n    \"osmextract\",\n    \"zonebuilder\"\n)\npak::pak(pkgs)\n\nYou should be able to generate the map on the next slide."
  },
  {
    "objectID": "slides/day1.html#setup-check-the-result",
    "href": "slides/day1.html#setup-check-the-result",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Setup check: The result",
    "text": "Setup check: The result"
  },
  {
    "objectID": "slides/day1.html#the-dstp-team",
    "href": "slides/day1.html#the-dstp-team",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "The DSTP Team",
    "text": "The DSTP Team\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource: GitHub"
  },
  {
    "objectID": "slides/day1.html#about-you",
    "href": "slides/day1.html#about-you",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "About you",
    "text": "About you\n\nName\nWhat tools you currently use for research\nWhere you’re from\nA random fact about you\n\nMe\n\nCurrently using VS Code, Quarto, R, Google Gemini etc, Devcontainers\nFrom Herefordshire, UK, work at the University of Leeds\n\nRandom fact: I run 5 km every Saturday with double buggy\n\nOver to you"
  },
  {
    "objectID": "slides/day1.html#the-origins-of-the-course",
    "href": "slides/day1.html#the-origins-of-the-course",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "The origins of the course",
    "text": "The origins of the course\n“If only I was told this earlier in my career”\nImagine a workflow that enabled:\n\nFewer context switches\nMore focus on the content and not style of the work\nIntegration of code into your research manuscript\nAutomatic generation of results that update when the data change\nControl over how you export and publish your work 😎\nFull reproducibility and control for maximum benefit 🚀"
  },
  {
    "objectID": "slides/day1.html#reproducible-workflows",
    "href": "slides/day1.html#reproducible-workflows",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Reproducible workflows",
    "text": "Reproducible workflows\n“Research is considered to be reproducible when the exact results can be reproduced if given access to the original data, software, or code.” Source: displayr.com"
  },
  {
    "objectID": "slides/day1.html#example-networkmerge",
    "href": "slides/day1.html#example-networkmerge",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Example: networkmerge",
    "text": "Example: networkmerge\n\nSee paper website: https://nptscot.github.io/networkmerge/ Source: github.com/nptscot"
  },
  {
    "objectID": "slides/day1.html#example-pct-npt-biclar-etc.",
    "href": "slides/day1.html#example-pct-npt-biclar-etc.",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Example: PCT, NPT, biclaR etc.",
    "text": "Example: PCT, NPT, biclaR etc.\n\nSee biclar.tmobilidade.pt source code: github.com/u-shift (félix2025?)."
  },
  {
    "objectID": "slides/day1.html#course-principles",
    "href": "slides/day1.html#course-principles",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Course principles",
    "text": "Course principles\n\n“Learn by doing”\n“Learn by teaching”\n“We’re all learning”\n“Can-do” and “Go for It” attitude\n“Every error is a learning opportunity”\n“No such thing as a bad question”\nBalance between focused work and comms"
  },
  {
    "objectID": "slides/day1.html#computational-infrastructure",
    "href": "slides/day1.html#computational-infrastructure",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Computational infrastructure",
    "text": "Computational infrastructure\nSource: “Dependency” by Randall Munroe: xkcd.com/2347/"
  },
  {
    "objectID": "slides/day1.html#which-ide-to-use-source-tdsciencecourse",
    "href": "slides/day1.html#which-ide-to-use-source-tdsciencecourse",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Which IDE to use? Source: tdscience/course",
    "text": "Which IDE to use? Source: tdscience/course"
  },
  {
    "objectID": "slides/day1.html#the-practical-sessions",
    "href": "slides/day1.html#the-practical-sessions",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "The practical sessions",
    "text": "The practical sessions\n\nTime of in-depth work\nUse the course website as a reference point but spend most of the time in your own environment\nWe will support people one-to-one and can do ‘live demos’\n\n\n\n\n\n\n\nTip\n\n\nPress Ctrl+Tab to switch from IDE to browser with course content and other things for an efficient workflow"
  },
  {
    "objectID": "slides/day1.html#set-up-project-folderrepo",
    "href": "slides/day1.html#set-up-project-folderrepo",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Set-up: project folder/repo",
    "text": "Set-up: project folder/repo\nOption 1: Create an empty folder on your computer (beginner level)\n\nVia Windows Explore or other GUI\nVia command line (e.g., mkdir dstp-rl, but replace ‘rl’ with your initials)\nVia RStudio or VS Code\n\nOption 2: Create a new repository on GitHub (more advanced, recommended)\n\nVia GitHub Desktop (beginner level)\nVia gh command line tool (more advanced, recommended)\n\ngh repo create dstp-rl --public --clone # replace 'rl' with your initials"
  },
  {
    "objectID": "slides/day1.html#tabsets",
    "href": "slides/day1.html#tabsets",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Tabsets",
    "text": "Tabsets\n\ngh CLI toolRShell\n\n\nThe following creates a fresh GitHub repo with GitHub CLI (recommended)\nNote: you need to have installed the GitHub CLI and authenticated it with your GitHub account.\ncd path/to/your/folder # e.g. cd C:/Users/YourName/Documents\ngh repo create dstp-rl --public --clone # replace 'rl' with your initials\ncode path/to/your/folder/dstp-rl # or open in RStudio\n\n\ndir.create(\"C:/path/to/your/folder/dstp\") # replace with your path\nrstudioapi::openProject(\"C:/path/to/your/folder/dstp\")\n\n\nThe following creates an empty folder with PowerShell or RStudio/VS Code terminal\n# After opening a terminal in your chosen IDE/shell\ncd path/to/your/folder # e.g. cd C:/Users/YourName/Documents\nmkdir dstp-rl # replace 'rl' with your initials\n# Then open the folder in your IDE"
  },
  {
    "objectID": "slides/day1.html#opening-your-project",
    "href": "slides/day1.html#opening-your-project",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Opening your project",
    "text": "Opening your project\nOption 1 (RStudio): Open the folder you created in RStudio using the New Project graphical interface menu\nOption 2 (RStudio - recommended): Open the folder you created in RStudio using the rstudioapi package, e.g. with the following command in R Console:\nrstudioapi::openProject(\"C:/path/to/your/folder/dstp\")\nOption 3: (VS Code): Open the folder you created in VS Code using the File &gt; Open Folder menu\ncode path/to/your/folder/dstp\nOption 4 (VS Code - recommended):\ncode path/to/your/folder/dstp"
  },
  {
    "objectID": "slides/day1.html#minimise-context-switching",
    "href": "slides/day1.html#minimise-context-switching",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Minimise context switching",
    "text": "Minimise context switching"
  },
  {
    "objectID": "slides/day1.html#any-questions-before-we-move-to-the-first-practical-session",
    "href": "slides/day1.html#any-questions-before-we-move-to-the-first-practical-session",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Any questions before we move to the first practical session?",
    "text": "Any questions before we move to the first practical session?"
  },
  {
    "objectID": "slides/day1.html#session-1-in-context",
    "href": "slides/day1.html#session-1-in-context",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Session 1 in context",
    "text": "Session 1 in context\n\n10:00-11:00 Introduction to Data Science for Transport Planning\n11:00-12:30 Finding, importing and cleaning transport datasets\n12:30-13:30 Lunch\n13:30-15:00 Origin-destination data analysis\n15:00-15:15 Break and refreshments\n15:15-17:00 OD Transport data visualisation"
  },
  {
    "objectID": "slides/day1.html#solo-working-through-the-practical-until-1230",
    "href": "slides/day1.html#solo-working-through-the-practical-until-1230",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Solo working through the practical (until ~12:30)",
    "text": "Solo working through the practical (until ~12:30)\nSee practical at tdscience.github.io/dstp/s1\nAny questions before the lunch break?\nPut your hands up, ask another participant, or use the github.com/tdscience/dstp/discussions"
  },
  {
    "objectID": "slides/day1.html#lunch-break-1230-1330",
    "href": "slides/day1.html#lunch-break-1230-1330",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Lunch break (12:30-13:30)",
    "text": "Lunch break (12:30-13:30)\nSee you back here at 13:30"
  },
  {
    "objectID": "slides/day1.html#lecture-on-session-2-od-and-geographic-data",
    "href": "slides/day1.html#lecture-on-session-2-od-and-geographic-data",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Lecture on Session 2: OD and geographic data",
    "text": "Lecture on Session 2: OD and geographic data\n\nOD data is implicitly geographic (Lovelace, Félix, and Carlino 2022)"
  },
  {
    "objectID": "slides/day1.html#running-rpython-code",
    "href": "slides/day1.html#running-rpython-code",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Running R/Python code",
    "text": "Running R/Python code\n\nRPython\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSee Yang’s slides in link at tdscience.github.io/dstp/s2"
  },
  {
    "objectID": "slides/day1.html#exercises",
    "href": "slides/day1.html#exercises",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Exercises",
    "text": "Exercises\nWork through the exercises in the Session 2 workbook\nAny questions before the break (15:00-15:15)?\n15:00-15:15 Break and refreshments"
  },
  {
    "objectID": "slides/day1.html#session-3",
    "href": "slides/day1.html#session-3",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "Session 3",
    "text": "Session 3\n\n15:15-17:00 OD Transport data visualisation\nSee Session 3 workbook"
  },
  {
    "objectID": "slides/day1.html#references",
    "href": "slides/day1.html#references",
    "title": "Data Science for Transport Planning: Day 1",
    "section": "References",
    "text": "References\n\n\n\n\nLovelace, Robin, Rosa Félix, and Dustin Carlino. 2022. “Jittering: A Computationally Efficient Method for Generating Realistic Route Networks from Origin-Destination Data.” Findings, April, 33873. https://doi.org/10.32866/001c.33873.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Münchow. 2025. Geocomputation with R. CRC Press. https://r.geocompx.org/."
  }
]